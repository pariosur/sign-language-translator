{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd52cc4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53569d45",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports\n",
    "\n",
    "Packages that need to be imported:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9965be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c9f46",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read dataframe\n",
    "\n",
    "Read json file with words and the list of videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ec5e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>instances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>[{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drink</td>\n",
       "      <td>[{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>before</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chair</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gloss                                          instances\n",
       "0      book  [{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...\n",
       "1     drink  [{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...\n",
       "2  computer  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...\n",
       "3    before  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...\n",
       "4     chair  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/dxli94/WLASL/master/start_kit/WLASL_v0.3.json\"\n",
    "df = pd.read_json(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98bac149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export a list of words in csv\n",
    "#df[\"gloss\"].to_csv(\"list_words.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34a0dd9",
   "metadata": {},
   "source": [
    "### Filter df only selected words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c543548",
   "metadata": {},
   "source": [
    "Filter the json file with words that will be used to train our model. This file will be used later to download the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb1ae99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>instances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>headache</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>cold</td>\n",
       "      <td>[{'bbox': [129, 16, 476, 370], 'fps': 25, 'fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tired</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>cough</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>heart</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gloss                                          instances\n",
       "117  headache  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...\n",
       "147      cold  [{'bbox': [129, 16, 476, 370], 'fps': 25, 'fra...\n",
       "175     tired  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...\n",
       "269     cough  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...\n",
       "287     heart  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_selected_words = [\"headache\", \"cough\", \"sore throat\", \"blood\", \"pregnant\", \"diabetes\", \n",
    "                       \"stomach\",\"pain\", \"allergy\", \"cold\", \"bone\",\"diarrhea\", \"heart\", \"heart attack\", \n",
    "                       \"cochlear implant\", \"vomit\", \"depressed\", \"hurt\", \"infection\", \"tired\", \"thank you\"]\n",
    "\n",
    "df = df[df['gloss'].isin(list_selected_words)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5d2c8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (21, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Df shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21de09ed",
   "metadata": {},
   "source": [
    "### Export pandas df to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a0cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_json = df.to_json(\"WLASL_v0.3.json\", orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c911748c",
   "metadata": {},
   "source": [
    "### Explore instances\n",
    "\n",
    "Create a dataframe with video_ids and the corresponding word. Notice that in this step we are using the json file exported in the previous step, which contains information about only 21 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303c95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = json.load(open(\"../scripts/WLASL_v0.3.json\"))\n",
    "\n",
    "id_videos = []\n",
    "for entry in content:\n",
    "    word = entry[\"gloss\"]\n",
    "    instances = entry['instances']\n",
    "\n",
    "    for inst in instances:\n",
    "        video_id = inst['video_id']\n",
    "        id_videos.append([word, video_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "408351a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>headache</td>\n",
       "      <td>26832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>headache</td>\n",
       "      <td>26835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>headache</td>\n",
       "      <td>26836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>headache</td>\n",
       "      <td>26837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>headache</td>\n",
       "      <td>26838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word video_id\n",
       "0  headache    26832\n",
       "1  headache    26835\n",
       "2  headache    26836\n",
       "3  headache    26837\n",
       "4  headache    26838"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_list = pd.DataFrame(id_videos, columns=[\"word\", \"video_id\"])\n",
    "id_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839dd32",
   "metadata": {},
   "source": [
    "Because of problems during download, we were not able to download all video_ids. To count the real number of videos that we have available, we need to check if they are in our folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f096e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number os videos: 154\n"
     ]
    }
   ],
   "source": [
    "ids_in_folder = []\n",
    "\n",
    "for video_id in id_list.video_id:\n",
    "    if os.path.exists(f'../raw_data/{video_id}.mp4'):\n",
    "        ids_in_folder.append(video_id)\n",
    "\n",
    "print(f\"Number os videos: {len(ids_in_folder)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6361477b",
   "metadata": {},
   "source": [
    "Filter dataframe to only videos available in our folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38f3f56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape new df: (154, 2)\n"
     ]
    }
   ],
   "source": [
    "id_list = id_list[id_list['video_id'].isin(ids_in_folder)]\n",
    "print(f\"Shape new df: {id_list.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29da871",
   "metadata": {},
   "source": [
    "#### Count videos per symptoms\n",
    "Check how many videos we have, by symptom, to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "777bc7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blood</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pain</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>thank you</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>infection</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>depressed</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pregnant</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>heart attack</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allergy</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hurt</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>diarrhea</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sore throat</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stomach</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cough</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cochlear implant</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tired</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>heart</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>headache</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vomit</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cold</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  video_id\n",
       "2               bone         4\n",
       "1              blood         5\n",
       "14              pain         6\n",
       "18         thank you         6\n",
       "13         infection         6\n",
       "6          depressed         6\n",
       "7           diabetes         6\n",
       "15          pregnant         6\n",
       "11      heart attack         6\n",
       "0            allergy         7\n",
       "12              hurt         7\n",
       "8           diarrhea         7\n",
       "16       sore throat         7\n",
       "17           stomach         8\n",
       "5              cough         8\n",
       "3   cochlear implant         8\n",
       "19             tired         8\n",
       "10             heart        10\n",
       "9           headache        10\n",
       "20             vomit        10\n",
       "4               cold        13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_list = id_list.groupby(\"word\").count().reset_index()\n",
    "aux_list.sort_values(\"video_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85311f2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf61e2",
   "metadata": {},
   "source": [
    "### Setup Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a0dc6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path for exported data, numpy arrays\n",
    "# DATA_PATH = os.path.join('../MP_Data') \n",
    "\n",
    "# # Videos are going to be 70 frames in length\n",
    "# sequence_length = 70 #wont be used anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ac548d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------------------------------\n",
    "# # Loop to create folders for each action to be trained\n",
    "# # and n_folder depending on the number of videos\n",
    "# # ----------------------------------------------------\n",
    "\n",
    "# for word in range(0, len(aux_list.word)):   # modificar range depois dos testes (0, len..)\n",
    "    \n",
    "#     # Identify how many videos per action\n",
    "#     n_folders = aux_list.iloc[word, 1]\n",
    "    \n",
    "#     # Create folders\n",
    "#     for n in range(n_folders):\n",
    "#         try:\n",
    "#             folder = os.path.join(DATA_PATH, aux_list.iloc[word, 0], str(n))\n",
    "#             os.makedirs(folder)\n",
    "#         except:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2f741",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions for data detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8df4283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12af1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa7fa2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.mediapipe_detection(image, model)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediapipe_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f14d98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b88f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9449099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e952f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Length Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efb9d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### To check lenght of videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6070511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract video id for selected word - Giovanna \n",
    "def videos_word(word):\n",
    "  \n",
    "    id_list_novo = id_list[id_list['word'] == word]\n",
    "    lista_videos = [video_id for video_id in id_list_novo.video_id]\n",
    "    \n",
    "    return lista_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "175eed33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>video_id</th>\n",
       "      <th>frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allergy</td>\n",
       "      <td>01962</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allergy</td>\n",
       "      <td>01955</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allergy</td>\n",
       "      <td>01965</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allergy</td>\n",
       "      <td>01956</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allergy</td>\n",
       "      <td>01957</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>vomit</td>\n",
       "      <td>61987</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>vomit</td>\n",
       "      <td>61990</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>vomit</td>\n",
       "      <td>61978</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>vomit</td>\n",
       "      <td>61979</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>vomit</td>\n",
       "      <td>61980</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      action video_id  frames\n",
       "0    allergy    01962    54.0\n",
       "1    allergy    01955   119.0\n",
       "2    allergy    01965   106.0\n",
       "3    allergy    01956    40.0\n",
       "4    allergy    01957   108.0\n",
       "..       ...      ...     ...\n",
       "149    vomit    61987    30.0\n",
       "150    vomit    61990    98.0\n",
       "151    vomit    61978   115.0\n",
       "152    vomit    61979    84.0\n",
       "153    vomit    61980    22.0\n",
       "\n",
       "[154 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to return duration and framecount for each video\n",
    "def with_opencv(filename):\n",
    "    import cv2\n",
    "    video = cv2.VideoCapture(filename)\n",
    "\n",
    "    duration = video.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    return duration, frame_count\n",
    "\n",
    "\n",
    "\n",
    "# Get id_videos from function video_words and return lenght\n",
    "n_frames = []\n",
    "teste = []\n",
    "\n",
    "for word in aux_list[\"word\"]:\n",
    "    for video_id in videos_word(word):\n",
    "        video = f'../raw_data/{video_id}.mp4'\n",
    "        frame_count = with_opencv(video)[1]\n",
    "        n_frames.append(frame_count)\n",
    "        teste.append([word, video_id, frame_count])\n",
    "        \n",
    "frames_words = pd.DataFrame(teste, columns=[\"action\", \"video_id\", \"frames\"])\n",
    "frames_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0968f4a1-5394-404e-829e-28285deeeae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distribution frames \n",
    "plt.title(\"Distribution of Frames\")\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(pd.DataFrame(n_frames), bins=30, color=\"g\", stacked=True);\n",
    "plt.text(80, 15, f'Optimal number \\n of frames=70');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92255e05-69eb-4587-90b1-ff397dc0d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve words, video, frames\n",
    "\n",
    "def words_video(word):\n",
    "    w = frames_words[frames_words['action'] == word].reset_index()\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5cf6a91-e825-4fd4-afbe-ccf164debf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>action</th>\n",
       "      <th>video_id</th>\n",
       "      <th>frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>cochlear implant</td>\n",
       "      <td>65373</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>cochlear implant</td>\n",
       "      <td>11498</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>cochlear implant</td>\n",
       "      <td>11499</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>cochlear implant</td>\n",
       "      <td>11500</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>cochlear implant</td>\n",
       "      <td>11501</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>cochlear implant</td>\n",
       "      <td>11502</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>cochlear implant</td>\n",
       "      <td>11503</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>cochlear implant</td>\n",
       "      <td>11504</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            action video_id  frames\n",
       "0     16  cochlear implant    65373    57.0\n",
       "1     17  cochlear implant    11498    98.0\n",
       "2     18  cochlear implant    11499    33.0\n",
       "3     19  cochlear implant    11500    32.0\n",
       "4     20  cochlear implant    11501   128.0\n",
       "5     21  cochlear implant    11502    65.0\n",
       "6     22  cochlear implant    11503    33.0\n",
       "7     23  cochlear implant    11504    50.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_video(\"cochlear implant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a56099-ae3a-43da-a532-e661b7aafa10",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Points - New"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b504e7e9-8da9-4b85-8178-1dc83895f743",
   "metadata": {},
   "source": [
    "#### Model Plan A - with loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32df1d80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Function to extract data points\n",
    "# Action = word\n",
    "# Folder = /word/number_folder\n",
    "# Video_id = name of the video\n",
    "# ---------------------------------------------------\n",
    "\n",
    "\n",
    "def extract_datapoints(action, folder, video_id, frames):\n",
    "    \n",
    "    data_path = os.path.join('../MP_Data')\n",
    "    \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "        for frame_num in range(frames):\n",
    "\n",
    "                    # Read feed\n",
    "                    ret, frame = cap.read()\n",
    "\n",
    "                    # Make detections\n",
    "                    try:\n",
    "                        image, results = mediapipe_detection(frame, holistic)\n",
    "                        print(results)\n",
    "\n",
    "                        # Draw landmarks and text\n",
    "                        draw_styled_landmarks(image, results)\n",
    "                        cv2.putText(image, 'Frames for {} video {}'.format(action, folder), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "                        # Show to screen\n",
    "                        cv2.imshow('OpenCV Feed', image)\n",
    "                        cv2.waitKey(500)\n",
    "\n",
    "                        # Export keypoints\n",
    "                        keypoints = extract_keypoints(results)\n",
    "                        npy_path = os.path.join(data_path, action, folder, str(frame_num))\n",
    "                        np.save(npy_path, keypoints)\n",
    "\n",
    "                        # Break gracefully\n",
    "                        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                            break\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26034625-57fb-41a1-9086-aaab8bb9b61f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ---------------------------------------------------\n",
    "# # Loop to extract data points using function\n",
    "# # ---------------------------------------------------\n",
    "\n",
    "# selected_word = [\"pregnant\"]\n",
    "\n",
    "# for word in selected_word:\n",
    "            \n",
    "#     # Filter the dataframe\n",
    "#     df_temp = frames_words[frames_words[\"action\"] == word] \n",
    "\n",
    "#     # Get information for each action\n",
    "#     for word in range(0, len(df_temp.action)):\n",
    "\n",
    "#         action = df_temp.iloc[word, 0]\n",
    "#         cap = cv2.VideoCapture(f\"../raw_data/{df_temp.iloc[word, 1]}.mp4\")\n",
    "#         sequence_folder = word\n",
    "#         frames = [int(df_temp.iloc[word, 2]) if int(df_temp.iloc[word, 2]) < 70 else 70][0]\n",
    "\n",
    "#         # Call the function to extract data points\n",
    "#         extract_datapoints(action, str(sequence_folder), cap, frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b51eae-ecac-4dfd-8ece-204f30d45481",
   "metadata": {},
   "source": [
    "#### Model  - Plan B "
   ]
  },
  {
   "cell_type": "raw",
   "id": "4362280f-e42c-442a-b9f3-4f58d6ee105d",
   "metadata": {
    "tags": []
   },
   "source": [
    "cap = cv2.VideoCapture(f'../raw_data/40807.mp4')\n",
    "ret, frame = cap.read()\n",
    "\n",
    "ret"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2683249c-f804-41d4-abd8-a6c50202a985",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set mediapipe model \n",
    "\n",
    "cap = cv2.VideoCapture(f'../raw_data/40807.mp4') # Video exemplo muito curto - 50 frames dÃ¡ erro!\n",
    "\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    data_path = os.path.join('../MP_Data')\n",
    "    \n",
    "    for frame_num in range(22):\n",
    "\n",
    "                # Read feed\n",
    "            \n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "                print(results)\n",
    "                \n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image, results)\n",
    "                \n",
    "                cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(\"teste\", 1), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 0, 255), 1, cv2.LINE_AA)\n",
    "                \n",
    "                 # Show to screen\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "                cv2.waitKey(500)\n",
    "                \n",
    "                \n",
    "                # Export keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(data_path, \"teste\", str(1), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4817d7-2663-409b-87fe-80879db71a72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Np array comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08b4cedd-3799-4f3d-9ebc-b7784a1a1460",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57193285  0.22017854 -1.21904743 ...  0.56454998  0.98780501\n",
      " -0.04535049]\n",
      "[ 0.57182086  0.22017053 -1.21666038 ...  0.56297451  0.98693269\n",
      " -0.04896437]\n",
      "[ 0.56920975  0.22020189 -1.22161901 ...  0.56155217  0.98782045\n",
      " -0.05091175]\n",
      "[ 0.56656766  0.22038238 -1.24134922 ...  0.56062192  0.9881565\n",
      " -0.04992827]\n",
      "[ 0.56610423  0.22070996 -1.25370991 ...  0.56032741  0.98862565\n",
      " -0.04985459]\n",
      "[ 0.56602693  0.22074513 -1.27188563 ...  0.56094748  0.98994315\n",
      " -0.04982345]\n",
      "[ 0.56592685  0.22074993 -1.27112269 ...  0.56134677  0.98916227\n",
      " -0.04781786]\n",
      "[ 0.56554478  0.22077982 -1.27350807 ...  0.5613519   0.98848212\n",
      " -0.04608831]\n",
      "[ 0.5652917   0.22078179 -1.26475048 ...  0.56149757  0.98836863\n",
      " -0.04495885]\n",
      "[ 0.56501824  0.22064899 -1.23950505 ...  0.56173271  0.98637193\n",
      " -0.04471043]\n",
      "[ 0.5646292   0.22006194 -1.23444712 ...  0.56119829  0.98530853\n",
      " -0.04455883]\n",
      "[ 0.56444931  0.21886954 -1.19446301 ...  0.56069505  0.98476136\n",
      " -0.04449674]\n",
      "[ 0.56355226  0.21670197 -1.2592721  ...  0.55945921  0.98532343\n",
      " -0.04669559]\n",
      "[ 0.56301636  0.21248497 -1.26818967 ...  0.55747271  0.98598492\n",
      " -0.04589119]\n",
      "[ 0.56240451  0.21015872 -1.27917624 ...  0.55605394  0.98601353\n",
      " -0.0462433 ]\n",
      "[ 0.56232399  0.20802282 -1.30001926 ...  0.55611736  0.98387033\n",
      " -0.0427687 ]\n",
      "[ 0.56266201  0.20569023 -1.29395413 ...  0.55712432  0.98274887\n",
      " -0.04333118]\n",
      "[ 0.56266177  0.20431902 -1.29890025 ...  0.55685377  0.98267347\n",
      " -0.04378572]\n",
      "[ 0.56319976  0.20287985 -1.31399846 ...  0.55711216  0.98259771\n",
      " -0.04232403]\n",
      "[ 0.56433219  0.20227005 -1.30475295 ...  0.55714077  0.98518485\n",
      " -0.04156206]\n",
      "[ 0.56465995  0.20227483 -1.30393195 ...  0.55649388  0.98797131\n",
      " -0.0431961 ]\n",
      "[ 0.5657537   0.20199779 -1.2668283  ...  0.55588865  0.99035227\n",
      " -0.04133258]\n",
      "[ 0.56733781  0.2019996  -1.23932838 ...  0.55685037  0.99224091\n",
      " -0.04200104]\n",
      "[ 0.56834853  0.20202707 -1.21181798 ...  0.55809331  0.99081522\n",
      " -0.03999439]\n",
      "[ 0.56999862  0.20302473 -1.25205278 ...  0.55831861  0.99236244\n",
      " -0.04249682]\n"
     ]
    }
   ],
   "source": [
    "# Sem loop\n",
    "for i in range(0, 25):\n",
    "    print(np.load(f\"../MP_Data/stomach/4/{i}.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc413cab-c9ac-40ad-bf02-1d45df25b2a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Com loop\n",
    "# for i in range(5, 15):\n",
    "#     print(np.load(f\"../MP_Data/teste/1/{i}.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861476eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Extract Data Points - Old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885387f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract data points from videos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f92a00f9-d9f2-4c72-9f4d-3c37751ffaeb",
   "metadata": {},
   "source": [
    "#extract_data_points(\"tired\", \"01960\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89d0bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------------------------------\n",
    "# #  Function to extract data points from videos\n",
    "# #  Action = words\n",
    "# #  Video_id = name of the video\n",
    "# #  Sequence = folder in which it will be placed\n",
    "# # ---------------------------------------------------\n",
    "\n",
    "# def extract_data_points(action, video_id, folder):\n",
    "    \n",
    "#     with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "#         for frame_num in range(sequence_length):\n",
    "            \n",
    "#             sequence = 1\n",
    "\n",
    "#             # Read feed\n",
    "#             cap = cv2.VideoCapture(f'../raw_data/{video_id}.mp4')\n",
    "#             ret, frame = cap.read()\n",
    "\n",
    "#             # Make detections\n",
    "#             image, results = mediapipe_detection(frame, holistic)\n",
    "#             print(results)\n",
    "\n",
    "#             # Draw landmarks\n",
    "#             draw_styled_landmarks(image, results)\n",
    "\n",
    "#             # Apply wait logic\n",
    "#             if frame_num == 0: \n",
    "#                 cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "#                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "#                 cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "#                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "#                 # Show to screen\n",
    "#                 cv2.imshow('OpenCV Feed', image)\n",
    "#                 cv2.waitKey(2000)\n",
    "#             else: \n",
    "#                 cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "#                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                 # Show to screen\n",
    "#                 cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "#             # Export keypoints\n",
    "#             keypoints = extract_keypoints(results)\n",
    "#             npy_path = os.path.join(DATA_PATH, action, str(folder), str(frame_num))\n",
    "#             np.save(npy_path, keypoints)\n",
    "\n",
    "#             # Break gracefully\n",
    "#             if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0dee095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------------------------------\n",
    "# # Loop to extract data points for each word and video\n",
    "# # and save it in the correct folder\n",
    "# # ---------------------------------------------------\n",
    "\n",
    "# for word in id_list.word.unique():\n",
    "    \n",
    "#     if word == \"tired\": #apagar depois dos testes, filtra apenas 1 palavra\n",
    "        \n",
    "#         # Filter the dataframe\n",
    "#         df_temp = id_list[id_list[\"word\"] == word] \n",
    "\n",
    "#         # Get information for each action\n",
    "#         for word in range(0, len(df_temp.word)):\n",
    "\n",
    "#             action = df_temp.iloc[word, 0]\n",
    "#             video_id = df_temp.iloc[word, 1]\n",
    "#             sequence = word\n",
    "\n",
    "#             # Call the function to extract data points\n",
    "#             extract_data_points(action, video_id, sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179848be",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract data points from webcam"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bbadaec-7f76-4ce7-ace4-643527a5592e",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------\n",
    "# Function to extract data points from webcam to\n",
    "# complement actions with less than x videos. This\n",
    "# function also creates additional folders\n",
    "\n",
    "# Action = list of words\n",
    "# no_sequence = number of additional videos to create\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def extract_data_points_webcam(actions, no_sequences):\n",
    "    \n",
    "    # Extract video from webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Set mediapipe model \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "        # Loop through actions\n",
    "        for action in actions:\n",
    "            \n",
    "            #Identify number of folders for this action\n",
    "            start_folder = int(max(os.listdir(f\"../MP_Data/{action}\")))+1\n",
    "            \n",
    "            # Loop through sequences aka videos\n",
    "            for sequence in range(start_folder, start_folder+no_sequences):\n",
    "                \n",
    "                # Create folder before export\n",
    "                os.makedirs(os.path.join(DATA_PATH, action, str(sequence))) \n",
    "                \n",
    "                # Loop through video length aka sequence length\n",
    "                for frame_num in range(sequence_length):\n",
    "\n",
    "                    # Read feed\n",
    "                    ret, frame = cap.read()\n",
    "\n",
    "                    # Make detections\n",
    "                    image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                    # Draw landmarks\n",
    "                    draw_styled_landmarks(image, results)\n",
    "\n",
    "                    # Apply wait logic\n",
    "                    if frame_num == 0: \n",
    "                        cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                        cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                        # Show to screen\n",
    "                        cv2.imshow('OpenCV Feed', image)\n",
    "                        cv2.waitKey(500)\n",
    "                    else: \n",
    "                        cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                        # Show to screen\n",
    "                        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                    # Export keypoints\n",
    "                    keypoints = extract_keypoints(results)                    \n",
    "                    npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                    np.save(npy_path, keypoints)\n",
    "\n",
    "                    # Break gracefully\n",
    "                    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                        break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "                    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3fdbd7a8-4384-4131-9cc5-38a41aac10f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ---------------------------------------------------\n",
    "# Create additional videos for selected words\n",
    "# ---------------------------------------------------\n",
    "\n",
    "list_words = [\"vomit\"]\n",
    "extract_data_points_webcam(list_words, 5)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3058c1b0-06a0-4ed6-9113-ec778cbcef4e",
   "metadata": {},
   "source": [
    "for word in id_list.word.unique():\n",
    "    \n",
    "    if word == \"tired\": #apagar depois dos testes, filtra apenas 1 palavra\n",
    "        \n",
    "        # Filter the dataframe\n",
    "        df_temp = id_list[id_list[\"word\"] == word] \n",
    "\n",
    "        # Get information for each action\n",
    "        for word in range(0, len(df_temp.word)):\n",
    "\n",
    "            action = df_temp.iloc[word, 0]\n",
    "            video_id = df_temp.iloc[word, 1]\n",
    "            sequence = word\n",
    "\n",
    "            # Call the function to extract data points\n",
    "            print(action, video_id, sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5dd0ff-9819-46d8-a90d-ecde1a6b0986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d5085ad",
   "metadata": {},
   "source": [
    "## Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9548bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46834ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['allergy', 'blood', 'bone', 'cochlear implant', 'cold', 'cough',\n",
       "       'depressed', 'diabetes', 'diarrhea', 'headache', 'heart',\n",
       "       'heart attack', 'hurt', 'infection', 'pain', 'pregnant',\n",
       "       'sore throat', 'stomach', 'thank you', 'tired', 'vomit'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.array(aux_list.word.tolist())\n",
    "\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a16a18b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c15066e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allergy': 0,\n",
       " 'blood': 1,\n",
       " 'bone': 2,\n",
       " 'cochlear implant': 3,\n",
       " 'cold': 4,\n",
       " 'cough': 5,\n",
       " 'depressed': 6,\n",
       " 'diabetes': 7,\n",
       " 'diarrhea': 8,\n",
       " 'headache': 9,\n",
       " 'heart': 10,\n",
       " 'heart attack': 11,\n",
       " 'hurt': 12,\n",
       " 'infection': 13,\n",
       " 'pain': 14,\n",
       " 'pregnant': 15,\n",
       " 'sore throat': 16,\n",
       " 'stomach': 17,\n",
       " 'thank you': 18,\n",
       " 'tired': 19,\n",
       " 'vomit': 20}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce55e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_videos = 3\n",
    "# seq_lenght_test = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "faef8b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53550684,  0.34136209, -0.61989337, ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/Users/pr/code/pariosur/sign-language-translator/MP_Data/bone/0/3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2707949f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4734031 ,  0.31705609, -0.72957027, ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/Users/pr/code/pariosur/sign-language-translator/MP_Data/bone/3/3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2348c08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      7\n",
       "1      5\n",
       "2      4\n",
       "3      8\n",
       "4     13\n",
       "5      8\n",
       "6      6\n",
       "7      6\n",
       "8      7\n",
       "9     10\n",
       "10    10\n",
       "11     6\n",
       "12     7\n",
       "13     6\n",
       "14     6\n",
       "15     6\n",
       "16     7\n",
       "17     8\n",
       "18     6\n",
       "19     8\n",
       "20    10\n",
       "Name: video_id, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_list.video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16d2ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1efa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "294b2375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pr/code/pariosur/sign-language-translator/notebooks'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "307f8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences = []\n",
    "\n",
    "# for action in actions:\n",
    "#     num_videos = len(os.listdir(f'../MP_Data/{action}'))-1\n",
    "    \n",
    "#     for video in range(num_videos):\n",
    "#         window = []\n",
    "#         num_of_frame = len(os.listdir(f'../MP_Data/{action}/{video}'))-1\n",
    "#         # video_array = np.load('../MP_Data/bone/0/3.npy') \n",
    "        \n",
    "#         for frame_num in range(num_of_frame):\n",
    "#             frame_array = np.load(f'../MP_Data/{action}/{video}/{frame_num}.npy')\n",
    "#             window.append(frame_array)\n",
    "            \n",
    "#         sequences.append(window)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ba1916",
   "metadata": {},
   "source": [
    "Code to create X,Y with Julien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4887ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences, labels = [],[]\n",
    "\n",
    "# for action in actions:\n",
    "#     num_videos = len(os.listdir(f'../MP_Data/{action}'))-1\n",
    "\n",
    "#     for video in range(num_videos):\n",
    "#         num_of_frame = len(os.listdir(f'../MP_Data/{action}/{video}'))-1\n",
    "#         window = []\n",
    "        \n",
    "#         for frame_num in range(num_of_frame):\n",
    "#             res = np.load(f'../MP_Data/{action}/{video}/{frame_num}.npy')\n",
    "#             window.append(res)\n",
    "#         sequences.append(window)\n",
    "#         labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed341ddf",
   "metadata": {},
   "source": [
    "Check the number of videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc4cf50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Function to extract path \n",
    "# from files to import. Returns\n",
    "# a list with path\n",
    "# -----------------------------\n",
    "\n",
    "def path_files(word, n_videos):\n",
    "    \n",
    "    all_files = []\n",
    "    \n",
    "    path = \"../MP_Data/\"\n",
    "    for n in range(int(n_videos)):\n",
    "        \n",
    "        single_videos = []\n",
    "        \n",
    "        temp_path = os.path.join(path, word, str(n))\n",
    "        list_files = os.listdir(temp_path)\n",
    "        \n",
    "        for file in list_files:\n",
    "            file_path = os.path.join(path, word, str(n), file)\n",
    "            single_videos.append(file_path)\n",
    "            \n",
    "        all_files.append(single_videos)\n",
    "        \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "735c487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Save in a dictionary the name \n",
    "# of action and all the files to\n",
    "# import\n",
    "# -----------------------------\n",
    "\n",
    "action_files = {}\n",
    "\n",
    "for line in range(len(aux_list)):\n",
    "    action = aux_list.iloc[line, 0]\n",
    "    n_videos = aux_list.iloc[line, 1]\n",
    "    \n",
    "    action_files[action] = path_files(action, n_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f752f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [] , []\n",
    "\n",
    "for action in action_files.keys():\n",
    "    \n",
    "    for file in action_files[action]:\n",
    "        \n",
    "        window = []\n",
    "        \n",
    "        for path in file:\n",
    "         \n",
    "            # Append X\n",
    "            array = np.load(path)\n",
    "            window.append(array)\n",
    "    \n",
    "        sequences.append(window)\n",
    "        \n",
    "        # Append y\n",
    "        labels.append(label_map.get(action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8d126cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/sgtlqx2s6gv_37hvp_91bw700000gn/T/ipykernel_25391/593582782.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  len(np.array(sequences))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84993a1",
   "metadata": {},
   "source": [
    "BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cb84b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53550684,  0.34136209, -0.61989337, ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('../MP_Data/bone/0/3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce6331db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/sgtlqx2s6gv_37hvp_91bw700000gn/T/ipykernel_25391/1188987122.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array(sequences).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(154,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce0b4644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff88a826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/sgtlqx2s6gv_37hvp_91bw700000gn/T/ipykernel_25391/2138012482.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X = np.array(sequences)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5a97dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c611afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pad = pad_sequences(X, dtype='float32',padding='post',maxlen=100, value=-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d518eec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 100, 1662)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a837c9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.5711082e-01,  2.8485426e-01, -6.5528876e-01, ...,\n",
       "         4.2869151e-01,  3.9285198e-01, -8.1399567e-03],\n",
       "       [ 4.8190647e-01,  2.8488854e-01, -4.9601805e-01, ...,\n",
       "         3.5632646e-01,  4.8288813e-01, -2.2695957e-02],\n",
       "       [ 4.8083374e-01,  2.8177437e-01, -4.1960186e-01, ...,\n",
       "         3.2050031e-01,  4.8421961e-01, -2.5204767e-02],\n",
       "       ...,\n",
       "       [-1.0000000e+03, -1.0000000e+03, -1.0000000e+03, ...,\n",
       "        -1.0000000e+03, -1.0000000e+03, -1.0000000e+03],\n",
       "       [-1.0000000e+03, -1.0000000e+03, -1.0000000e+03, ...,\n",
       "        -1.0000000e+03, -1.0000000e+03, -1.0000000e+03],\n",
       "       [-1.0000000e+03, -1.0000000e+03, -1.0000000e+03, ...,\n",
       "        -1.0000000e+03, -1.0000000e+03, -1.0000000e+03]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b7cc934",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b8a0847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d26a6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b327ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 100, 1662)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "661c40d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 21)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c4695",
   "metadata": {},
   "source": [
    "## Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87cf8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, GRU\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Masking\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc15a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a7020a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 11:23:48.096872: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-09-02 11:23:48.096964: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-09-02 11:23:48.099068: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e42bd6d",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3bdbf6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 11:23:49.190522: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value=-1000))\n",
    "model.add(GRU(32, return_sequences=False, activation='relu', input_shape=(100,1662)))\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05839f4",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3de7e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value=-1000))\n",
    "model.add(GRU(32, return_sequences=False, activation='relu', input_shape=(100,1662)))\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d910c8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44da9821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7, 0.2, 0.1]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [.7, 0.2, 0.1]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab30847f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'allergy'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c78bc944",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da064474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 11:24:11.556990: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "6/6 [==============================] - 1s 70ms/step - loss: 3.1440 - categorical_accuracy: 0.0116 - val_loss: 3.0288 - val_categorical_accuracy: 0.0811\n",
      "Epoch 2/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.0468 - categorical_accuracy: 0.0581 - val_loss: 3.0683 - val_categorical_accuracy: 0.0541\n",
      "Epoch 3/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.0425 - categorical_accuracy: 0.0698 - val_loss: 3.0278 - val_categorical_accuracy: 0.1351\n",
      "Epoch 4/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.0752 - categorical_accuracy: 0.0465 - val_loss: 3.0812 - val_categorical_accuracy: 0.0270\n",
      "Epoch 5/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.0372 - categorical_accuracy: 0.0581 - val_loss: 3.0772 - val_categorical_accuracy: 0.0270\n",
      "Epoch 6/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.0470 - categorical_accuracy: 0.0698 - val_loss: 3.0563 - val_categorical_accuracy: 0.0270\n",
      "Epoch 7/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.0368 - categorical_accuracy: 0.0581 - val_loss: 3.0950 - val_categorical_accuracy: 0.0270\n",
      "Epoch 8/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.0350 - categorical_accuracy: 0.0581 - val_loss: 3.0686 - val_categorical_accuracy: 0.0270\n",
      "Epoch 9/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.0331 - categorical_accuracy: 0.0581 - val_loss: 3.0673 - val_categorical_accuracy: 0.0270\n",
      "Epoch 10/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.0207 - categorical_accuracy: 0.0814 - val_loss: 3.0430 - val_categorical_accuracy: 0.1351\n",
      "Epoch 11/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.0279 - categorical_accuracy: 0.0465 - val_loss: 3.1164 - val_categorical_accuracy: 0.0270\n",
      "Epoch 12/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.0181 - categorical_accuracy: 0.0581 - val_loss: 3.0899 - val_categorical_accuracy: 0.0270\n",
      "Epoch 13/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.0052 - categorical_accuracy: 0.0814 - val_loss: 3.1494 - val_categorical_accuracy: 0.0270\n",
      "Epoch 14/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.0088 - categorical_accuracy: 0.0581 - val_loss: 3.0476 - val_categorical_accuracy: 0.0270\n",
      "Epoch 15/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.9960 - categorical_accuracy: 0.0814 - val_loss: 3.0269 - val_categorical_accuracy: 0.1081\n",
      "Epoch 16/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.9977 - categorical_accuracy: 0.0930 - val_loss: 3.0278 - val_categorical_accuracy: 0.0541\n",
      "Epoch 17/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.9758 - categorical_accuracy: 0.1163 - val_loss: 3.0484 - val_categorical_accuracy: 0.0270\n",
      "Epoch 18/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.9737 - categorical_accuracy: 0.1163 - val_loss: 3.0704 - val_categorical_accuracy: 0.0270\n",
      "Epoch 19/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.9486 - categorical_accuracy: 0.0814 - val_loss: 3.0453 - val_categorical_accuracy: 0.0541\n",
      "Epoch 20/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.9588 - categorical_accuracy: 0.1047 - val_loss: 3.0674 - val_categorical_accuracy: 0.0541\n",
      "Epoch 21/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.9298 - categorical_accuracy: 0.1047 - val_loss: 3.0363 - val_categorical_accuracy: 0.0270\n",
      "Epoch 22/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.9074 - categorical_accuracy: 0.1163 - val_loss: 3.0216 - val_categorical_accuracy: 0.0270\n",
      "Epoch 23/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.9176 - categorical_accuracy: 0.1163 - val_loss: 2.9970 - val_categorical_accuracy: 0.0811\n",
      "Epoch 24/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.8887 - categorical_accuracy: 0.1163 - val_loss: 3.0491 - val_categorical_accuracy: 0.0541\n",
      "Epoch 25/2000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 2.8730 - categorical_accuracy: 0.1163 - val_loss: 3.0108 - val_categorical_accuracy: 0.0541\n",
      "Epoch 26/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.8727 - categorical_accuracy: 0.1163 - val_loss: 3.0186 - val_categorical_accuracy: 0.0541\n",
      "Epoch 27/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.8413 - categorical_accuracy: 0.1163 - val_loss: 3.0415 - val_categorical_accuracy: 0.0541\n",
      "Epoch 28/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.8457 - categorical_accuracy: 0.1279 - val_loss: 3.0114 - val_categorical_accuracy: 0.0811\n",
      "Epoch 29/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.8172 - categorical_accuracy: 0.1163 - val_loss: 3.0113 - val_categorical_accuracy: 0.1081\n",
      "Epoch 30/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.7995 - categorical_accuracy: 0.1047 - val_loss: 3.0212 - val_categorical_accuracy: 0.0270\n",
      "Epoch 31/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.8090 - categorical_accuracy: 0.1395 - val_loss: 3.0036 - val_categorical_accuracy: 0.1081\n",
      "Epoch 32/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.8084 - categorical_accuracy: 0.1163 - val_loss: 3.0254 - val_categorical_accuracy: 0.0541\n",
      "Epoch 33/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.7946 - categorical_accuracy: 0.1279 - val_loss: 3.0001 - val_categorical_accuracy: 0.0811\n",
      "Epoch 34/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.7454 - categorical_accuracy: 0.1163 - val_loss: 3.0200 - val_categorical_accuracy: 0.1351\n",
      "Epoch 35/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.7373 - categorical_accuracy: 0.1047 - val_loss: 3.0543 - val_categorical_accuracy: 0.0270\n",
      "Epoch 36/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.7375 - categorical_accuracy: 0.1744 - val_loss: 3.0095 - val_categorical_accuracy: 0.0811\n",
      "Epoch 37/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.7135 - categorical_accuracy: 0.0930 - val_loss: 2.9798 - val_categorical_accuracy: 0.1081\n",
      "Epoch 38/2000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.6891 - categorical_accuracy: 0.1047 - val_loss: 3.0400 - val_categorical_accuracy: 0.0541\n",
      "Epoch 39/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.7050 - categorical_accuracy: 0.1163 - val_loss: 3.0560 - val_categorical_accuracy: 0.0811\n",
      "Epoch 40/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.7011 - categorical_accuracy: 0.1279 - val_loss: 2.9808 - val_categorical_accuracy: 0.1351\n",
      "Epoch 41/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.6966 - categorical_accuracy: 0.1163 - val_loss: 2.9904 - val_categorical_accuracy: 0.1081\n",
      "Epoch 42/2000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.6484 - categorical_accuracy: 0.1279 - val_loss: 3.0853 - val_categorical_accuracy: 0.0541\n",
      "Epoch 43/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.6651 - categorical_accuracy: 0.1279 - val_loss: 3.0324 - val_categorical_accuracy: 0.0811\n",
      "Epoch 44/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.6468 - categorical_accuracy: 0.1163 - val_loss: 3.0783 - val_categorical_accuracy: 0.0541\n",
      "Epoch 45/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.6471 - categorical_accuracy: 0.1744 - val_loss: 3.0183 - val_categorical_accuracy: 0.1081\n",
      "Epoch 46/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.6107 - categorical_accuracy: 0.1279 - val_loss: 3.1252 - val_categorical_accuracy: 0.0811\n",
      "Epoch 47/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.6250 - categorical_accuracy: 0.1395 - val_loss: 3.0658 - val_categorical_accuracy: 0.0811\n",
      "Epoch 48/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.6000 - categorical_accuracy: 0.1279 - val_loss: 3.2292 - val_categorical_accuracy: 0.0270\n",
      "Epoch 49/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.5923 - categorical_accuracy: 0.1395 - val_loss: 3.0584 - val_categorical_accuracy: 0.0541\n",
      "Epoch 50/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 38ms/step - loss: 2.5881 - categorical_accuracy: 0.1279 - val_loss: 2.9850 - val_categorical_accuracy: 0.1081\n",
      "Epoch 51/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.5573 - categorical_accuracy: 0.1279 - val_loss: 3.0659 - val_categorical_accuracy: 0.0541\n",
      "Epoch 52/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.5726 - categorical_accuracy: 0.1279 - val_loss: 3.0297 - val_categorical_accuracy: 0.0811\n",
      "Epoch 53/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.5334 - categorical_accuracy: 0.1512 - val_loss: 3.2967 - val_categorical_accuracy: 0.0541\n",
      "Epoch 54/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.6112 - categorical_accuracy: 0.1163 - val_loss: 2.9846 - val_categorical_accuracy: 0.0811\n",
      "Epoch 55/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.5199 - categorical_accuracy: 0.1628 - val_loss: 2.9674 - val_categorical_accuracy: 0.0541\n",
      "Epoch 56/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.5394 - categorical_accuracy: 0.1512 - val_loss: 3.0509 - val_categorical_accuracy: 0.0541\n",
      "Epoch 57/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.4974 - categorical_accuracy: 0.1279 - val_loss: 3.2870 - val_categorical_accuracy: 0.0811\n",
      "Epoch 58/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.6412 - categorical_accuracy: 0.1628 - val_loss: 2.9887 - val_categorical_accuracy: 0.0541\n",
      "Epoch 59/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.5252 - categorical_accuracy: 0.1628 - val_loss: 3.0050 - val_categorical_accuracy: 0.0811\n",
      "Epoch 60/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.4698 - categorical_accuracy: 0.1860 - val_loss: 3.0921 - val_categorical_accuracy: 0.0811\n",
      "Epoch 61/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.4773 - categorical_accuracy: 0.1512 - val_loss: 3.0566 - val_categorical_accuracy: 0.0541\n",
      "Epoch 62/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.4766 - categorical_accuracy: 0.1628 - val_loss: 3.2160 - val_categorical_accuracy: 0.0541\n",
      "Epoch 63/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.4938 - categorical_accuracy: 0.1279 - val_loss: 2.9904 - val_categorical_accuracy: 0.0541\n",
      "Epoch 64/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.4700 - categorical_accuracy: 0.1628 - val_loss: 3.0266 - val_categorical_accuracy: 0.0541\n",
      "Epoch 65/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.4393 - categorical_accuracy: 0.1628 - val_loss: 3.1368 - val_categorical_accuracy: 0.0811\n",
      "Epoch 66/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.4616 - categorical_accuracy: 0.1512 - val_loss: 3.0192 - val_categorical_accuracy: 0.0811\n",
      "Epoch 67/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.4120 - categorical_accuracy: 0.1977 - val_loss: 3.1400 - val_categorical_accuracy: 0.1081\n",
      "Epoch 68/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.4403 - categorical_accuracy: 0.1977 - val_loss: 3.0461 - val_categorical_accuracy: 0.0811\n",
      "Epoch 69/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.4242 - categorical_accuracy: 0.1628 - val_loss: 3.0131 - val_categorical_accuracy: 0.0541\n",
      "Epoch 70/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.3966 - categorical_accuracy: 0.1744 - val_loss: 3.0645 - val_categorical_accuracy: 0.0541\n",
      "Epoch 71/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.3874 - categorical_accuracy: 0.1977 - val_loss: 3.2030 - val_categorical_accuracy: 0.0811\n",
      "Epoch 72/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.3905 - categorical_accuracy: 0.1860 - val_loss: 3.0619 - val_categorical_accuracy: 0.0541\n",
      "Epoch 73/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.3686 - categorical_accuracy: 0.1744 - val_loss: 3.0734 - val_categorical_accuracy: 0.0541\n",
      "Epoch 74/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.3866 - categorical_accuracy: 0.1860 - val_loss: 3.0542 - val_categorical_accuracy: 0.0541\n",
      "Epoch 75/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.3924 - categorical_accuracy: 0.1628 - val_loss: 3.0861 - val_categorical_accuracy: 0.0270\n",
      "Epoch 76/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.3594 - categorical_accuracy: 0.1977 - val_loss: 3.0524 - val_categorical_accuracy: 0.0541\n",
      "Epoch 77/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.3523 - categorical_accuracy: 0.1977 - val_loss: 3.0990 - val_categorical_accuracy: 0.0541\n",
      "Epoch 78/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.3292 - categorical_accuracy: 0.2093 - val_loss: 3.4164 - val_categorical_accuracy: 0.0541\n",
      "Epoch 79/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.3975 - categorical_accuracy: 0.1744 - val_loss: 3.2576 - val_categorical_accuracy: 0.0270\n",
      "Epoch 80/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.3348 - categorical_accuracy: 0.2209 - val_loss: 3.2461 - val_categorical_accuracy: 0.0270\n",
      "Epoch 81/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.3360 - categorical_accuracy: 0.1860 - val_loss: 3.1662 - val_categorical_accuracy: 0.0541\n",
      "Epoch 82/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.3380 - categorical_accuracy: 0.1977 - val_loss: 3.0744 - val_categorical_accuracy: 0.0541\n",
      "Epoch 83/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.3280 - categorical_accuracy: 0.1628 - val_loss: 3.3530 - val_categorical_accuracy: 0.0811\n",
      "Epoch 84/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.3384 - categorical_accuracy: 0.2558 - val_loss: 3.0792 - val_categorical_accuracy: 0.0541\n",
      "Epoch 85/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.2895 - categorical_accuracy: 0.2093 - val_loss: 3.0908 - val_categorical_accuracy: 0.0541\n",
      "Epoch 86/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.2925 - categorical_accuracy: 0.2442 - val_loss: 3.0720 - val_categorical_accuracy: 0.1081\n",
      "Epoch 87/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.2991 - categorical_accuracy: 0.2093 - val_loss: 3.1784 - val_categorical_accuracy: 0.0541\n",
      "Epoch 88/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.2552 - categorical_accuracy: 0.2326 - val_loss: 3.1307 - val_categorical_accuracy: 0.0541\n",
      "Epoch 89/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.2894 - categorical_accuracy: 0.2209 - val_loss: 3.2536 - val_categorical_accuracy: 0.0541\n",
      "Epoch 90/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.2258 - categorical_accuracy: 0.3023 - val_loss: 3.6845 - val_categorical_accuracy: 0.1081\n",
      "Epoch 91/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.4172 - categorical_accuracy: 0.2442 - val_loss: 3.1483 - val_categorical_accuracy: 0.0541\n",
      "Epoch 92/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.2248 - categorical_accuracy: 0.2907 - val_loss: 3.2719 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 93/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.2330 - categorical_accuracy: 0.3140 - val_loss: 3.2226 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 94/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.2061 - categorical_accuracy: 0.2209 - val_loss: 3.2443 - val_categorical_accuracy: 0.0541\n",
      "Epoch 95/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.2002 - categorical_accuracy: 0.2674 - val_loss: 3.2348 - val_categorical_accuracy: 0.0541\n",
      "Epoch 96/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.2487 - categorical_accuracy: 0.2558 - val_loss: 3.1528 - val_categorical_accuracy: 0.0541\n",
      "Epoch 97/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.1782 - categorical_accuracy: 0.3023 - val_loss: 3.3262 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 98/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.1680 - categorical_accuracy: 0.2558 - val_loss: 3.3355 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 99/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 44ms/step - loss: 2.1651 - categorical_accuracy: 0.2907 - val_loss: 3.2234 - val_categorical_accuracy: 0.0811\n",
      "Epoch 100/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.1666 - categorical_accuracy: 0.2558 - val_loss: 3.5598 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 101/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.2688 - categorical_accuracy: 0.2442 - val_loss: 3.1930 - val_categorical_accuracy: 0.0541\n",
      "Epoch 102/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.1250 - categorical_accuracy: 0.3140 - val_loss: 3.4278 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 103/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.1629 - categorical_accuracy: 0.2907 - val_loss: 3.4585 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 104/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.1102 - categorical_accuracy: 0.2674 - val_loss: 3.3209 - val_categorical_accuracy: 0.0541\n",
      "Epoch 105/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.1037 - categorical_accuracy: 0.2907 - val_loss: 3.6067 - val_categorical_accuracy: 0.0541\n",
      "Epoch 106/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.3300 - categorical_accuracy: 0.2442 - val_loss: 3.2437 - val_categorical_accuracy: 0.0541\n",
      "Epoch 107/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.0756 - categorical_accuracy: 0.3023 - val_loss: 3.3316 - val_categorical_accuracy: 0.0541\n",
      "Epoch 108/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.1154 - categorical_accuracy: 0.2674 - val_loss: 3.3882 - val_categorical_accuracy: 0.0541\n",
      "Epoch 109/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.0686 - categorical_accuracy: 0.3023 - val_loss: 3.3127 - val_categorical_accuracy: 0.0270\n",
      "Epoch 110/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.0664 - categorical_accuracy: 0.3023 - val_loss: 3.2880 - val_categorical_accuracy: 0.0270\n",
      "Epoch 111/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.1116 - categorical_accuracy: 0.2558 - val_loss: 3.3356 - val_categorical_accuracy: 0.0541\n",
      "Epoch 112/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.0718 - categorical_accuracy: 0.2791 - val_loss: 3.2609 - val_categorical_accuracy: 0.0541\n",
      "Epoch 113/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.0468 - categorical_accuracy: 0.3140 - val_loss: 3.6272 - val_categorical_accuracy: 0.0270\n",
      "Epoch 114/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.0297 - categorical_accuracy: 0.2791 - val_loss: 3.9576 - val_categorical_accuracy: 0.1081\n",
      "Epoch 115/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.1928 - categorical_accuracy: 0.3023 - val_loss: 3.5718 - val_categorical_accuracy: 0.0270\n",
      "Epoch 116/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.0548 - categorical_accuracy: 0.3488 - val_loss: 3.2986 - val_categorical_accuracy: 0.0541\n",
      "Epoch 117/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.0174 - categorical_accuracy: 0.3023 - val_loss: 3.4371 - val_categorical_accuracy: 0.0270\n",
      "Epoch 118/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.9850 - categorical_accuracy: 0.3488 - val_loss: 3.4246 - val_categorical_accuracy: 0.0270\n",
      "Epoch 119/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.1609 - categorical_accuracy: 0.2791 - val_loss: 3.2780 - val_categorical_accuracy: 0.0811\n",
      "Epoch 120/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.0103 - categorical_accuracy: 0.3023 - val_loss: 3.7908 - val_categorical_accuracy: 0.0270\n",
      "Epoch 121/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.9905 - categorical_accuracy: 0.3372 - val_loss: 3.2600 - val_categorical_accuracy: 0.0541\n",
      "Epoch 122/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.0017 - categorical_accuracy: 0.3023 - val_loss: 3.3875 - val_categorical_accuracy: 0.0541\n",
      "Epoch 123/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.9682 - categorical_accuracy: 0.3023 - val_loss: 3.3781 - val_categorical_accuracy: 0.0811\n",
      "Epoch 124/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.9697 - categorical_accuracy: 0.3140 - val_loss: 3.4437 - val_categorical_accuracy: 0.0270\n",
      "Epoch 125/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.0120 - categorical_accuracy: 0.2907 - val_loss: 3.4886 - val_categorical_accuracy: 0.0811\n",
      "Epoch 126/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.9593 - categorical_accuracy: 0.3372 - val_loss: 4.0356 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 127/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.9565 - categorical_accuracy: 0.3372 - val_loss: 3.3270 - val_categorical_accuracy: 0.1081\n",
      "Epoch 128/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.9621 - categorical_accuracy: 0.3140 - val_loss: 3.3836 - val_categorical_accuracy: 0.0811\n",
      "Epoch 129/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.1129 - categorical_accuracy: 0.2907 - val_loss: 3.2179 - val_categorical_accuracy: 0.0541\n",
      "Epoch 130/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.9048 - categorical_accuracy: 0.3605 - val_loss: 3.4377 - val_categorical_accuracy: 0.0541\n",
      "Epoch 131/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.9012 - categorical_accuracy: 0.3488 - val_loss: 3.5254 - val_categorical_accuracy: 0.0811\n",
      "Epoch 132/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.9527 - categorical_accuracy: 0.3605 - val_loss: 3.7967 - val_categorical_accuracy: 0.0541\n",
      "Epoch 133/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.9172 - categorical_accuracy: 0.3372 - val_loss: 3.2890 - val_categorical_accuracy: 0.0811\n",
      "Epoch 134/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.9300 - categorical_accuracy: 0.3721 - val_loss: 3.8588 - val_categorical_accuracy: 0.0270\n",
      "Epoch 135/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.8782 - categorical_accuracy: 0.3837 - val_loss: 3.8004 - val_categorical_accuracy: 0.0541\n",
      "Epoch 136/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.9156 - categorical_accuracy: 0.3837 - val_loss: 3.8149 - val_categorical_accuracy: 0.0811\n",
      "Epoch 137/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.9749 - categorical_accuracy: 0.3023 - val_loss: 3.4971 - val_categorical_accuracy: 0.0541\n",
      "Epoch 138/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.8675 - categorical_accuracy: 0.3837 - val_loss: 3.4155 - val_categorical_accuracy: 0.1081\n",
      "Epoch 139/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.8390 - categorical_accuracy: 0.3721 - val_loss: 4.0229 - val_categorical_accuracy: 0.0270\n",
      "Epoch 140/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.9044 - categorical_accuracy: 0.3488 - val_loss: 3.8222 - val_categorical_accuracy: 0.0541\n",
      "Epoch 141/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.8736 - categorical_accuracy: 0.3256 - val_loss: 3.9024 - val_categorical_accuracy: 0.0270\n",
      "Epoch 142/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.8340 - categorical_accuracy: 0.4186 - val_loss: 3.6007 - val_categorical_accuracy: 0.0541\n",
      "Epoch 143/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.8533 - categorical_accuracy: 0.4186 - val_loss: 3.4679 - val_categorical_accuracy: 0.1622\n",
      "Epoch 144/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.8323 - categorical_accuracy: 0.3721 - val_loss: 3.8917 - val_categorical_accuracy: 0.1081\n",
      "Epoch 145/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.9064 - categorical_accuracy: 0.4186 - val_loss: 3.4782 - val_categorical_accuracy: 0.1081\n",
      "Epoch 146/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.8374 - categorical_accuracy: 0.4070 - val_loss: 3.7474 - val_categorical_accuracy: 0.0541\n",
      "Epoch 147/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.8426 - categorical_accuracy: 0.3837 - val_loss: 3.8051 - val_categorical_accuracy: 0.0270\n",
      "Epoch 148/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 36ms/step - loss: 1.7627 - categorical_accuracy: 0.4186 - val_loss: 3.5435 - val_categorical_accuracy: 0.1622\n",
      "Epoch 149/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.7826 - categorical_accuracy: 0.4651 - val_loss: 3.8056 - val_categorical_accuracy: 0.0811\n",
      "Epoch 150/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.7399 - categorical_accuracy: 0.4186 - val_loss: 3.5678 - val_categorical_accuracy: 0.1081\n",
      "Epoch 151/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.7668 - categorical_accuracy: 0.3837 - val_loss: 3.7330 - val_categorical_accuracy: 0.0541\n",
      "Epoch 152/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.8264 - categorical_accuracy: 0.4070 - val_loss: 4.3031 - val_categorical_accuracy: 0.1081\n",
      "Epoch 153/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.8308 - categorical_accuracy: 0.3721 - val_loss: 3.6545 - val_categorical_accuracy: 0.1622\n",
      "Epoch 154/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.7404 - categorical_accuracy: 0.4535 - val_loss: 3.9451 - val_categorical_accuracy: 0.0541\n",
      "Epoch 155/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.7427 - categorical_accuracy: 0.4535 - val_loss: 4.0249 - val_categorical_accuracy: 0.0811\n",
      "Epoch 156/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.7119 - categorical_accuracy: 0.3721 - val_loss: 3.8175 - val_categorical_accuracy: 0.1081\n",
      "Epoch 157/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.7318 - categorical_accuracy: 0.3837 - val_loss: 3.6713 - val_categorical_accuracy: 0.1081\n",
      "Epoch 158/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.6798 - categorical_accuracy: 0.4651 - val_loss: 4.0649 - val_categorical_accuracy: 0.0541\n",
      "Epoch 159/2000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.7280 - categorical_accuracy: 0.4186 - val_loss: 3.7604 - val_categorical_accuracy: 0.1892\n",
      "Epoch 160/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.7940 - categorical_accuracy: 0.4419 - val_loss: 3.5711 - val_categorical_accuracy: 0.0541\n",
      "Epoch 161/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.7501 - categorical_accuracy: 0.4302 - val_loss: 3.6466 - val_categorical_accuracy: 0.1351\n",
      "Epoch 162/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.7499 - categorical_accuracy: 0.3837 - val_loss: 3.4739 - val_categorical_accuracy: 0.1622\n",
      "Epoch 163/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.8160 - categorical_accuracy: 0.3721 - val_loss: 3.4474 - val_categorical_accuracy: 0.0811\n",
      "Epoch 164/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.7397 - categorical_accuracy: 0.4302 - val_loss: 3.5928 - val_categorical_accuracy: 0.2162\n",
      "Epoch 165/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.7494 - categorical_accuracy: 0.3953 - val_loss: 3.4751 - val_categorical_accuracy: 0.1892\n",
      "Epoch 166/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.6739 - categorical_accuracy: 0.4070 - val_loss: 3.7519 - val_categorical_accuracy: 0.1892\n",
      "Epoch 167/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.6939 - categorical_accuracy: 0.4651 - val_loss: 4.5308 - val_categorical_accuracy: 0.0270\n",
      "Epoch 168/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.6995 - categorical_accuracy: 0.4302 - val_loss: 4.1079 - val_categorical_accuracy: 0.0541\n",
      "Epoch 169/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.7599 - categorical_accuracy: 0.4302 - val_loss: 4.0074 - val_categorical_accuracy: 0.0811\n",
      "Epoch 170/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.6115 - categorical_accuracy: 0.4651 - val_loss: 4.0588 - val_categorical_accuracy: 0.1622\n",
      "Epoch 171/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.7259 - categorical_accuracy: 0.3837 - val_loss: 3.7855 - val_categorical_accuracy: 0.1622\n",
      "Epoch 172/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.5846 - categorical_accuracy: 0.4302 - val_loss: 3.8494 - val_categorical_accuracy: 0.1351\n",
      "Epoch 173/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.6270 - categorical_accuracy: 0.3721 - val_loss: 3.8945 - val_categorical_accuracy: 0.1351\n",
      "Epoch 174/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.6173 - categorical_accuracy: 0.4186 - val_loss: 4.1737 - val_categorical_accuracy: 0.0270\n",
      "Epoch 175/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.5786 - categorical_accuracy: 0.3953 - val_loss: 3.9053 - val_categorical_accuracy: 0.1351\n",
      "Epoch 176/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.6523 - categorical_accuracy: 0.4651 - val_loss: 4.3917 - val_categorical_accuracy: 0.0811\n",
      "Epoch 177/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.6952 - categorical_accuracy: 0.3372 - val_loss: 3.8951 - val_categorical_accuracy: 0.0811\n",
      "Epoch 178/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.5923 - categorical_accuracy: 0.4186 - val_loss: 4.0785 - val_categorical_accuracy: 0.1081\n",
      "Epoch 179/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.5472 - categorical_accuracy: 0.4419 - val_loss: 3.9418 - val_categorical_accuracy: 0.0811\n",
      "Epoch 180/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.5260 - categorical_accuracy: 0.4535 - val_loss: 3.8352 - val_categorical_accuracy: 0.0541\n",
      "Epoch 181/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.7698 - categorical_accuracy: 0.3605 - val_loss: 3.8672 - val_categorical_accuracy: 0.1081\n",
      "Epoch 182/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.5118 - categorical_accuracy: 0.5116 - val_loss: 3.7717 - val_categorical_accuracy: 0.1351\n",
      "Epoch 183/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.5164 - categorical_accuracy: 0.5349 - val_loss: 3.8922 - val_categorical_accuracy: 0.1622\n",
      "Epoch 184/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.5109 - categorical_accuracy: 0.5116 - val_loss: 4.2169 - val_categorical_accuracy: 0.1081\n",
      "Epoch 185/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.5942 - categorical_accuracy: 0.4302 - val_loss: 3.5880 - val_categorical_accuracy: 0.2162\n",
      "Epoch 186/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.4572 - categorical_accuracy: 0.5581 - val_loss: 4.8889 - val_categorical_accuracy: 0.0811\n",
      "Epoch 187/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.6365 - categorical_accuracy: 0.4535 - val_loss: 4.0479 - val_categorical_accuracy: 0.0811\n",
      "Epoch 188/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.4303 - categorical_accuracy: 0.5349 - val_loss: 3.7309 - val_categorical_accuracy: 0.0811\n",
      "Epoch 189/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.6547 - categorical_accuracy: 0.5116 - val_loss: 4.0037 - val_categorical_accuracy: 0.0541\n",
      "Epoch 190/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.7249 - categorical_accuracy: 0.4070 - val_loss: 4.1258 - val_categorical_accuracy: 0.0811\n",
      "Epoch 191/2000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.6760 - categorical_accuracy: 0.4535 - val_loss: 4.1279 - val_categorical_accuracy: 0.0541\n",
      "Epoch 192/2000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.4970 - categorical_accuracy: 0.5000 - val_loss: 4.2143 - val_categorical_accuracy: 0.1081\n",
      "Epoch 193/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.5493 - categorical_accuracy: 0.5000 - val_loss: 3.7959 - val_categorical_accuracy: 0.0811\n",
      "Epoch 194/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.3765 - categorical_accuracy: 0.5814 - val_loss: 5.1353 - val_categorical_accuracy: 0.1081\n",
      "Epoch 195/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.6482 - categorical_accuracy: 0.4302 - val_loss: 4.0468 - val_categorical_accuracy: 0.1622\n",
      "Epoch 196/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.4693 - categorical_accuracy: 0.5116 - val_loss: 4.3922 - val_categorical_accuracy: 0.0541\n",
      "Epoch 197/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 38ms/step - loss: 1.6233 - categorical_accuracy: 0.4535 - val_loss: 5.2217 - val_categorical_accuracy: 0.0541\n",
      "Epoch 198/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.7942 - categorical_accuracy: 0.3837 - val_loss: 5.2085 - val_categorical_accuracy: 0.1351\n",
      "Epoch 199/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.4848 - categorical_accuracy: 0.5349 - val_loss: 4.5281 - val_categorical_accuracy: 0.0811\n",
      "Epoch 200/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.3877 - categorical_accuracy: 0.5233 - val_loss: 4.1842 - val_categorical_accuracy: 0.1081\n",
      "Epoch 201/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.3739 - categorical_accuracy: 0.5233 - val_loss: 3.9881 - val_categorical_accuracy: 0.0811\n",
      "Epoch 202/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.3757 - categorical_accuracy: 0.5349 - val_loss: 3.9846 - val_categorical_accuracy: 0.1622\n",
      "Epoch 203/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.5070 - categorical_accuracy: 0.5000 - val_loss: 3.8151 - val_categorical_accuracy: 0.0811\n",
      "Epoch 204/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.4831 - categorical_accuracy: 0.4884 - val_loss: 4.5274 - val_categorical_accuracy: 0.1081\n",
      "Epoch 205/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.3209 - categorical_accuracy: 0.5930 - val_loss: 4.5086 - val_categorical_accuracy: 0.0811\n",
      "Epoch 206/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.3871 - categorical_accuracy: 0.5465 - val_loss: 4.1336 - val_categorical_accuracy: 0.0541\n",
      "Epoch 207/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.4622 - categorical_accuracy: 0.4767 - val_loss: 4.2231 - val_categorical_accuracy: 0.0541\n",
      "Epoch 208/2000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.3152 - categorical_accuracy: 0.5465 - val_loss: 4.1945 - val_categorical_accuracy: 0.1081\n",
      "Epoch 209/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.3810 - categorical_accuracy: 0.5581 - val_loss: 4.3710 - val_categorical_accuracy: 0.1351\n",
      "Epoch 210/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.3948 - categorical_accuracy: 0.5349 - val_loss: 4.6983 - val_categorical_accuracy: 0.0541\n",
      "Epoch 211/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.4664 - categorical_accuracy: 0.5349 - val_loss: 4.6687 - val_categorical_accuracy: 0.1081\n",
      "Epoch 212/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.2066 - categorical_accuracy: 0.5930 - val_loss: 4.4118 - val_categorical_accuracy: 0.1892\n",
      "Epoch 213/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.3967 - categorical_accuracy: 0.5116 - val_loss: 4.5842 - val_categorical_accuracy: 0.1081\n",
      "Epoch 214/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.2849 - categorical_accuracy: 0.5930 - val_loss: 4.2993 - val_categorical_accuracy: 0.1081\n",
      "Epoch 215/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.3401 - categorical_accuracy: 0.6047 - val_loss: 4.1989 - val_categorical_accuracy: 0.1892\n",
      "Epoch 216/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.4156 - categorical_accuracy: 0.5000 - val_loss: 4.2027 - val_categorical_accuracy: 0.0811\n",
      "Epoch 217/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.5540 - categorical_accuracy: 0.4767 - val_loss: 4.9426 - val_categorical_accuracy: 0.1351\n",
      "Epoch 218/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.3709 - categorical_accuracy: 0.5233 - val_loss: 4.5077 - val_categorical_accuracy: 0.1081\n",
      "Epoch 219/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.3304 - categorical_accuracy: 0.6163 - val_loss: 4.1123 - val_categorical_accuracy: 0.1351\n",
      "Epoch 220/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.2974 - categorical_accuracy: 0.5814 - val_loss: 4.7363 - val_categorical_accuracy: 0.1351\n",
      "Epoch 221/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.2323 - categorical_accuracy: 0.6047 - val_loss: 4.4667 - val_categorical_accuracy: 0.1351\n",
      "Epoch 222/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.1633 - categorical_accuracy: 0.6744 - val_loss: 5.2557 - val_categorical_accuracy: 0.0811\n",
      "Epoch 223/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.4163 - categorical_accuracy: 0.5349 - val_loss: 4.6267 - val_categorical_accuracy: 0.1892\n",
      "Epoch 224/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.3476 - categorical_accuracy: 0.5814 - val_loss: 4.4703 - val_categorical_accuracy: 0.1622\n",
      "Epoch 225/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.1893 - categorical_accuracy: 0.6395 - val_loss: 4.9888 - val_categorical_accuracy: 0.1081\n",
      "Epoch 226/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.4544 - categorical_accuracy: 0.4767 - val_loss: 4.7635 - val_categorical_accuracy: 0.1081\n",
      "Epoch 227/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.1584 - categorical_accuracy: 0.6279 - val_loss: 4.8736 - val_categorical_accuracy: 0.1081\n",
      "Epoch 228/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.1903 - categorical_accuracy: 0.5349 - val_loss: 4.3209 - val_categorical_accuracy: 0.1622\n",
      "Epoch 229/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.1931 - categorical_accuracy: 0.5698 - val_loss: 4.1340 - val_categorical_accuracy: 0.0811\n",
      "Epoch 230/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.4108 - categorical_accuracy: 0.5000 - val_loss: 5.3244 - val_categorical_accuracy: 0.1622\n",
      "Epoch 231/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.6685 - categorical_accuracy: 0.4186 - val_loss: 4.7759 - val_categorical_accuracy: 0.1351\n",
      "Epoch 232/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.1394 - categorical_accuracy: 0.6512 - val_loss: 4.4662 - val_categorical_accuracy: 0.1622\n",
      "Epoch 233/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.1054 - categorical_accuracy: 0.6279 - val_loss: 4.6200 - val_categorical_accuracy: 0.1081\n",
      "Epoch 234/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.1656 - categorical_accuracy: 0.5581 - val_loss: 4.6681 - val_categorical_accuracy: 0.1351\n",
      "Epoch 235/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.1613 - categorical_accuracy: 0.5814 - val_loss: 4.7424 - val_categorical_accuracy: 0.1081\n",
      "Epoch 236/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.2187 - categorical_accuracy: 0.6279 - val_loss: 5.3724 - val_categorical_accuracy: 0.2162\n",
      "Epoch 237/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.3730 - categorical_accuracy: 0.5581 - val_loss: 5.2409 - val_categorical_accuracy: 0.1081\n",
      "Epoch 238/2000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.2726 - categorical_accuracy: 0.5814 - val_loss: 5.0786 - val_categorical_accuracy: 0.1622\n",
      "Epoch 239/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.2653 - categorical_accuracy: 0.5930 - val_loss: 4.4459 - val_categorical_accuracy: 0.1622\n",
      "Epoch 240/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.1728 - categorical_accuracy: 0.6163 - val_loss: 5.1867 - val_categorical_accuracy: 0.1622\n",
      "Epoch 241/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.2811 - categorical_accuracy: 0.6047 - val_loss: 4.4066 - val_categorical_accuracy: 0.1622\n",
      "Epoch 242/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.2684 - categorical_accuracy: 0.5930 - val_loss: 5.6813 - val_categorical_accuracy: 0.0811\n",
      "Epoch 243/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.2128 - categorical_accuracy: 0.2674 - val_loss: 4.9224 - val_categorical_accuracy: 0.1351\n",
      "Epoch 244/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.4959 - categorical_accuracy: 0.4535 - val_loss: 4.8809 - val_categorical_accuracy: 0.0811\n",
      "Epoch 245/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.3031 - categorical_accuracy: 0.5698 - val_loss: 5.1005 - val_categorical_accuracy: 0.1622\n",
      "Epoch 246/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 35ms/step - loss: 1.1845 - categorical_accuracy: 0.6395 - val_loss: 4.8782 - val_categorical_accuracy: 0.1622\n",
      "Epoch 247/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.1028 - categorical_accuracy: 0.7093 - val_loss: 5.0885 - val_categorical_accuracy: 0.1351\n",
      "Epoch 248/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.0769 - categorical_accuracy: 0.6163 - val_loss: 4.8952 - val_categorical_accuracy: 0.1622\n",
      "Epoch 249/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.1285 - categorical_accuracy: 0.6279 - val_loss: 5.5506 - val_categorical_accuracy: 0.1622\n",
      "Epoch 250/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.2372 - categorical_accuracy: 0.5698 - val_loss: 5.2161 - val_categorical_accuracy: 0.0811\n",
      "Epoch 251/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.1499 - categorical_accuracy: 0.6163 - val_loss: 5.0246 - val_categorical_accuracy: 0.1622\n",
      "Epoch 252/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.0272 - categorical_accuracy: 0.6860 - val_loss: 4.7945 - val_categorical_accuracy: 0.1351\n",
      "Epoch 253/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.0737 - categorical_accuracy: 0.6860 - val_loss: 4.8965 - val_categorical_accuracy: 0.1081\n",
      "Epoch 254/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.0616 - categorical_accuracy: 0.6744 - val_loss: 5.2285 - val_categorical_accuracy: 0.1622\n",
      "Epoch 255/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.0783 - categorical_accuracy: 0.6860 - val_loss: 5.4036 - val_categorical_accuracy: 0.0811\n",
      "Epoch 256/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.9571 - categorical_accuracy: 0.6977 - val_loss: 5.5121 - val_categorical_accuracy: 0.0811\n",
      "Epoch 257/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.4741 - categorical_accuracy: 0.5698 - val_loss: 4.4003 - val_categorical_accuracy: 0.1892\n",
      "Epoch 258/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.0395 - categorical_accuracy: 0.6628 - val_loss: 5.4851 - val_categorical_accuracy: 0.1351\n",
      "Epoch 259/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.9644 - categorical_accuracy: 0.6744 - val_loss: 4.9902 - val_categorical_accuracy: 0.1351\n",
      "Epoch 260/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.2419 - categorical_accuracy: 0.5930 - val_loss: 4.9767 - val_categorical_accuracy: 0.1351\n",
      "Epoch 261/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.3008 - categorical_accuracy: 0.5116 - val_loss: 4.6518 - val_categorical_accuracy: 0.1081\n",
      "Epoch 262/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.0210 - categorical_accuracy: 0.6860 - val_loss: 5.2520 - val_categorical_accuracy: 0.1622\n",
      "Epoch 263/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.9423 - categorical_accuracy: 0.7209 - val_loss: 5.1464 - val_categorical_accuracy: 0.1351\n",
      "Epoch 264/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.1449 - categorical_accuracy: 0.6628 - val_loss: 5.1757 - val_categorical_accuracy: 0.1081\n",
      "Epoch 265/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.2650 - categorical_accuracy: 0.5465 - val_loss: 4.3023 - val_categorical_accuracy: 0.1351\n",
      "Epoch 266/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.0614 - categorical_accuracy: 0.6628 - val_loss: 4.6569 - val_categorical_accuracy: 0.1081\n",
      "Epoch 267/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.0834 - categorical_accuracy: 0.6047 - val_loss: 4.7007 - val_categorical_accuracy: 0.1351\n",
      "Epoch 268/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.9634 - categorical_accuracy: 0.6744 - val_loss: 5.5018 - val_categorical_accuracy: 0.1081\n",
      "Epoch 269/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.9658 - categorical_accuracy: 0.6977 - val_loss: 4.7745 - val_categorical_accuracy: 0.1081\n",
      "Epoch 270/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.4630 - categorical_accuracy: 0.4651 - val_loss: 5.4601 - val_categorical_accuracy: 0.1081\n",
      "Epoch 271/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.0160 - categorical_accuracy: 0.6977 - val_loss: 4.6740 - val_categorical_accuracy: 0.1081\n",
      "Epoch 272/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.9598 - categorical_accuracy: 0.7209 - val_loss: 5.1039 - val_categorical_accuracy: 0.1351\n",
      "Epoch 273/2000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.9277 - categorical_accuracy: 0.6628 - val_loss: 4.6131 - val_categorical_accuracy: 0.1081\n",
      "Epoch 274/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.8776 - categorical_accuracy: 0.6860 - val_loss: 5.1014 - val_categorical_accuracy: 0.1081\n",
      "Epoch 275/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.1800 - categorical_accuracy: 0.6628 - val_loss: 4.7771 - val_categorical_accuracy: 0.1081\n",
      "Epoch 276/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.1826 - categorical_accuracy: 0.5465 - val_loss: 4.5097 - val_categorical_accuracy: 0.1351\n",
      "Epoch 277/2000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.9263 - categorical_accuracy: 0.7093 - val_loss: 5.2373 - val_categorical_accuracy: 0.1351\n",
      "Epoch 278/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.0165 - categorical_accuracy: 0.6860 - val_loss: 5.5350 - val_categorical_accuracy: 0.0811\n",
      "Epoch 279/2000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.0136 - categorical_accuracy: 0.6395 - val_loss: 5.3153 - val_categorical_accuracy: 0.0541\n",
      "Epoch 280/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.9110 - categorical_accuracy: 0.6628 - val_loss: 5.5185 - val_categorical_accuracy: 0.0811\n",
      "Epoch 281/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.0189 - categorical_accuracy: 0.6047 - val_loss: 5.6847 - val_categorical_accuracy: 0.0811\n",
      "Epoch 282/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.9767 - categorical_accuracy: 0.6395 - val_loss: 6.3719 - val_categorical_accuracy: 0.1351\n",
      "Epoch 283/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.9487 - categorical_accuracy: 0.6395 - val_loss: 7.1308 - val_categorical_accuracy: 0.0811\n",
      "Epoch 284/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.0870 - categorical_accuracy: 0.6860 - val_loss: 5.1911 - val_categorical_accuracy: 0.1081\n",
      "Epoch 285/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.8749 - categorical_accuracy: 0.6744 - val_loss: 4.9896 - val_categorical_accuracy: 0.1351\n",
      "Epoch 286/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.9054 - categorical_accuracy: 0.6977 - val_loss: 5.4436 - val_categorical_accuracy: 0.1081\n",
      "Epoch 287/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.9103 - categorical_accuracy: 0.6860 - val_loss: 5.8692 - val_categorical_accuracy: 0.1351\n",
      "Epoch 288/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.8393 - categorical_accuracy: 0.7209 - val_loss: 5.5402 - val_categorical_accuracy: 0.0811\n",
      "Epoch 289/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.7975 - categorical_accuracy: 0.7442 - val_loss: 5.7187 - val_categorical_accuracy: 0.1081\n",
      "Epoch 290/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.8225 - categorical_accuracy: 0.6977 - val_loss: 5.7502 - val_categorical_accuracy: 0.1351\n",
      "Epoch 291/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.2166 - categorical_accuracy: 0.5465 - val_loss: 4.3441 - val_categorical_accuracy: 0.2162\n",
      "Epoch 292/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.9566 - categorical_accuracy: 0.6395 - val_loss: 5.8130 - val_categorical_accuracy: 0.0811\n",
      "Epoch 293/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.9482 - categorical_accuracy: 0.6628 - val_loss: 5.5976 - val_categorical_accuracy: 0.1081\n",
      "Epoch 294/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.8341 - categorical_accuracy: 0.7326 - val_loss: 6.0102 - val_categorical_accuracy: 0.1892\n",
      "Epoch 295/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 37ms/step - loss: 0.7429 - categorical_accuracy: 0.7558 - val_loss: 5.3434 - val_categorical_accuracy: 0.1351\n",
      "Epoch 296/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.9974 - categorical_accuracy: 0.6860 - val_loss: 5.1753 - val_categorical_accuracy: 0.1351\n",
      "Epoch 297/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.0582 - categorical_accuracy: 0.5814 - val_loss: 5.1686 - val_categorical_accuracy: 0.1081\n",
      "Epoch 298/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.7804 - categorical_accuracy: 0.7558 - val_loss: 6.6854 - val_categorical_accuracy: 0.1081\n",
      "Epoch 299/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.1629 - categorical_accuracy: 0.5930 - val_loss: 6.4577 - val_categorical_accuracy: 0.0811\n",
      "Epoch 300/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.3176 - categorical_accuracy: 0.5233 - val_loss: 4.8613 - val_categorical_accuracy: 0.1351\n",
      "Epoch 301/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.9562 - categorical_accuracy: 0.6977 - val_loss: 6.6587 - val_categorical_accuracy: 0.1351\n",
      "Epoch 302/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.8352 - categorical_accuracy: 0.7209 - val_loss: 5.4073 - val_categorical_accuracy: 0.1622\n",
      "Epoch 303/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.7057 - categorical_accuracy: 0.7558 - val_loss: 6.1600 - val_categorical_accuracy: 0.1081\n",
      "Epoch 304/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.7808 - categorical_accuracy: 0.7674 - val_loss: 5.8946 - val_categorical_accuracy: 0.1081\n",
      "Epoch 305/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.9705 - categorical_accuracy: 0.6744 - val_loss: 5.2172 - val_categorical_accuracy: 0.1351\n",
      "Epoch 306/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.7626 - categorical_accuracy: 0.7674 - val_loss: 5.5667 - val_categorical_accuracy: 0.1622\n",
      "Epoch 307/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.8779 - categorical_accuracy: 0.6977 - val_loss: 5.4741 - val_categorical_accuracy: 0.1351\n",
      "Epoch 308/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.7856 - categorical_accuracy: 0.7558 - val_loss: 6.6503 - val_categorical_accuracy: 0.1622\n",
      "Epoch 309/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.7929 - categorical_accuracy: 0.6744 - val_loss: 6.9532 - val_categorical_accuracy: 0.1351\n",
      "Epoch 310/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.7876 - categorical_accuracy: 0.6977 - val_loss: 6.4785 - val_categorical_accuracy: 0.1351\n",
      "Epoch 311/2000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.9292 - categorical_accuracy: 0.6977 - val_loss: 5.3643 - val_categorical_accuracy: 0.1081\n",
      "Epoch 312/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.7954 - categorical_accuracy: 0.6860 - val_loss: 6.7526 - val_categorical_accuracy: 0.1081\n",
      "Epoch 313/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.3562 - categorical_accuracy: 0.5930 - val_loss: 5.0214 - val_categorical_accuracy: 0.0541\n",
      "Epoch 314/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.8257 - categorical_accuracy: 0.7209 - val_loss: 5.5209 - val_categorical_accuracy: 0.1351\n",
      "Epoch 315/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.7578 - categorical_accuracy: 0.7093 - val_loss: 6.3163 - val_categorical_accuracy: 0.1081\n",
      "Epoch 316/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.8323 - categorical_accuracy: 0.7558 - val_loss: 6.2901 - val_categorical_accuracy: 0.1081\n",
      "Epoch 317/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.0945 - categorical_accuracy: 0.6977 - val_loss: 5.6631 - val_categorical_accuracy: 0.1351\n",
      "Epoch 318/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.0333 - categorical_accuracy: 0.6628 - val_loss: 6.5830 - val_categorical_accuracy: 0.0811\n",
      "Epoch 319/2000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.9618 - categorical_accuracy: 0.7093 - val_loss: 6.1341 - val_categorical_accuracy: 0.1351\n",
      "Epoch 320/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.8413 - categorical_accuracy: 0.7558 - val_loss: 5.6551 - val_categorical_accuracy: 0.1081\n",
      "Epoch 321/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.8605 - categorical_accuracy: 0.6628 - val_loss: 5.5881 - val_categorical_accuracy: 0.1081\n",
      "Epoch 322/2000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.7234 - categorical_accuracy: 0.7791 - val_loss: 5.6966 - val_categorical_accuracy: 0.1351\n",
      "Epoch 323/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.7825 - categorical_accuracy: 0.7442 - val_loss: 6.0458 - val_categorical_accuracy: 0.1622\n",
      "Epoch 324/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.8897 - categorical_accuracy: 0.6395 - val_loss: 6.5414 - val_categorical_accuracy: 0.1351\n",
      "Epoch 325/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6778 - categorical_accuracy: 0.7907 - val_loss: 6.4222 - val_categorical_accuracy: 0.1622\n",
      "Epoch 326/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6794 - categorical_accuracy: 0.7674 - val_loss: 6.9953 - val_categorical_accuracy: 0.0541\n",
      "Epoch 327/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.3166 - categorical_accuracy: 0.6163 - val_loss: 5.7816 - val_categorical_accuracy: 0.1081\n",
      "Epoch 328/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.7531 - categorical_accuracy: 0.7442 - val_loss: 6.4687 - val_categorical_accuracy: 0.1081\n",
      "Epoch 329/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.1477 - categorical_accuracy: 0.6163 - val_loss: 5.8557 - val_categorical_accuracy: 0.1351\n",
      "Epoch 330/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6587 - categorical_accuracy: 0.8023 - val_loss: 7.2241 - val_categorical_accuracy: 0.1622\n",
      "Epoch 331/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.6561 - categorical_accuracy: 0.7558 - val_loss: 6.2736 - val_categorical_accuracy: 0.1081\n",
      "Epoch 332/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.7359 - categorical_accuracy: 0.7558 - val_loss: 7.7187 - val_categorical_accuracy: 0.1622\n",
      "Epoch 333/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.6792 - categorical_accuracy: 0.4767 - val_loss: 5.9938 - val_categorical_accuracy: 0.1622\n",
      "Epoch 334/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.8187 - categorical_accuracy: 0.6860 - val_loss: 6.7250 - val_categorical_accuracy: 0.0811\n",
      "Epoch 335/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.5659 - categorical_accuracy: 0.8140 - val_loss: 6.2141 - val_categorical_accuracy: 0.1892\n",
      "Epoch 336/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.8076 - categorical_accuracy: 0.7093 - val_loss: 6.7249 - val_categorical_accuracy: 0.1622\n",
      "Epoch 337/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6581 - categorical_accuracy: 0.7674 - val_loss: 6.7354 - val_categorical_accuracy: 0.1892\n",
      "Epoch 338/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.6351 - categorical_accuracy: 0.7674 - val_loss: 6.8436 - val_categorical_accuracy: 0.1892\n",
      "Epoch 339/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.8574 - categorical_accuracy: 0.7558 - val_loss: 5.5684 - val_categorical_accuracy: 0.0811\n",
      "Epoch 340/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.8272 - categorical_accuracy: 0.6977 - val_loss: 7.7133 - val_categorical_accuracy: 0.1622\n",
      "Epoch 341/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.8316 - categorical_accuracy: 0.6977 - val_loss: 5.8941 - val_categorical_accuracy: 0.1622\n",
      "Epoch 342/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.6024 - categorical_accuracy: 0.8256 - val_loss: 6.4279 - val_categorical_accuracy: 0.1081\n",
      "Epoch 343/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.1680 - categorical_accuracy: 0.6395 - val_loss: 6.1979 - val_categorical_accuracy: 0.1622\n",
      "Epoch 344/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 35ms/step - loss: 0.5460 - categorical_accuracy: 0.8140 - val_loss: 7.1076 - val_categorical_accuracy: 0.1622\n",
      "Epoch 345/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.7556 - categorical_accuracy: 0.7791 - val_loss: 6.7497 - val_categorical_accuracy: 0.1081\n",
      "Epoch 346/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.8721 - categorical_accuracy: 0.7442 - val_loss: 7.1200 - val_categorical_accuracy: 0.1081\n",
      "Epoch 347/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.9498 - categorical_accuracy: 0.7326 - val_loss: 6.7730 - val_categorical_accuracy: 0.0811\n",
      "Epoch 348/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.8385 - categorical_accuracy: 0.6860 - val_loss: 6.7398 - val_categorical_accuracy: 0.1081\n",
      "Epoch 349/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.6221 - categorical_accuracy: 0.8023 - val_loss: 7.1138 - val_categorical_accuracy: 0.1892\n",
      "Epoch 350/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.5105 - categorical_accuracy: 0.8488 - val_loss: 8.3022 - val_categorical_accuracy: 0.1081\n",
      "Epoch 351/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.5939 - categorical_accuracy: 0.5930 - val_loss: 6.6941 - val_categorical_accuracy: 0.0811\n",
      "Epoch 352/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.5578 - categorical_accuracy: 0.8372 - val_loss: 7.1195 - val_categorical_accuracy: 0.1081\n",
      "Epoch 353/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.5159 - categorical_accuracy: 0.7907 - val_loss: 6.9678 - val_categorical_accuracy: 0.1892\n",
      "Epoch 354/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.5889 - categorical_accuracy: 0.7791 - val_loss: 6.6062 - val_categorical_accuracy: 0.1622\n",
      "Epoch 355/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.0646 - categorical_accuracy: 0.6163 - val_loss: 5.8282 - val_categorical_accuracy: 0.1622\n",
      "Epoch 356/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6817 - categorical_accuracy: 0.7209 - val_loss: 7.1922 - val_categorical_accuracy: 0.1081\n",
      "Epoch 357/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.4888 - categorical_accuracy: 0.8372 - val_loss: 7.1210 - val_categorical_accuracy: 0.1351\n",
      "Epoch 358/2000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.5966 - categorical_accuracy: 0.8256 - val_loss: 7.0690 - val_categorical_accuracy: 0.1351\n",
      "Epoch 359/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.7482 - categorical_accuracy: 0.7442 - val_loss: 6.6556 - val_categorical_accuracy: 0.1081\n",
      "Epoch 360/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.5302 - categorical_accuracy: 0.8140 - val_loss: 6.2826 - val_categorical_accuracy: 0.1351\n",
      "Epoch 361/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.2168 - categorical_accuracy: 0.6860 - val_loss: 5.7124 - val_categorical_accuracy: 0.1351\n",
      "Epoch 362/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.7513 - categorical_accuracy: 0.7326 - val_loss: 6.8107 - val_categorical_accuracy: 0.1892\n",
      "Epoch 363/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.5917 - categorical_accuracy: 0.8256 - val_loss: 8.4626 - val_categorical_accuracy: 0.1622\n",
      "Epoch 364/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.2325 - categorical_accuracy: 0.6279 - val_loss: 8.2122 - val_categorical_accuracy: 0.1622\n",
      "Epoch 365/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.6669 - categorical_accuracy: 0.7209 - val_loss: 6.4252 - val_categorical_accuracy: 0.1622\n",
      "Epoch 366/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.5047 - categorical_accuracy: 0.8488 - val_loss: 6.8173 - val_categorical_accuracy: 0.1351\n",
      "Epoch 367/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.4825 - categorical_accuracy: 0.8140 - val_loss: 8.5363 - val_categorical_accuracy: 0.0541\n",
      "Epoch 368/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.6829 - categorical_accuracy: 0.7442 - val_loss: 7.7117 - val_categorical_accuracy: 0.1622\n",
      "Epoch 369/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.5151 - categorical_accuracy: 0.7791 - val_loss: 8.5314 - val_categorical_accuracy: 0.1081\n",
      "Epoch 370/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.5907 - categorical_accuracy: 0.7442 - val_loss: 6.3157 - val_categorical_accuracy: 0.1351\n",
      "Epoch 371/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.4545 - categorical_accuracy: 0.8488 - val_loss: 7.3270 - val_categorical_accuracy: 0.1351\n",
      "Epoch 372/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.6694 - categorical_accuracy: 0.8023 - val_loss: 6.9239 - val_categorical_accuracy: 0.0811\n",
      "Epoch 373/2000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.7565 - categorical_accuracy: 0.7326 - val_loss: 7.7817 - val_categorical_accuracy: 0.1351\n",
      "Epoch 374/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.9789 - categorical_accuracy: 0.7442 - val_loss: 6.3237 - val_categorical_accuracy: 0.1351\n",
      "Epoch 375/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.7785 - categorical_accuracy: 0.7326 - val_loss: 7.1046 - val_categorical_accuracy: 0.1892\n",
      "Epoch 376/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6384 - categorical_accuracy: 0.8023 - val_loss: 7.4412 - val_categorical_accuracy: 0.1081\n",
      "Epoch 377/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.2481 - categorical_accuracy: 0.5581 - val_loss: 6.6059 - val_categorical_accuracy: 0.1622\n",
      "Epoch 378/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.5576 - categorical_accuracy: 0.8372 - val_loss: 7.1947 - val_categorical_accuracy: 0.1892\n",
      "Epoch 379/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.4431 - categorical_accuracy: 0.8605 - val_loss: 7.2924 - val_categorical_accuracy: 0.1892\n",
      "Epoch 380/2000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.5243 - categorical_accuracy: 0.7791 - val_loss: 6.4244 - val_categorical_accuracy: 0.1351\n",
      "Epoch 381/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.7929 - categorical_accuracy: 0.6977 - val_loss: 9.0941 - val_categorical_accuracy: 0.1081\n",
      "Epoch 382/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.6569 - categorical_accuracy: 0.8140 - val_loss: 8.4467 - val_categorical_accuracy: 0.0541\n",
      "Epoch 383/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.5953 - categorical_accuracy: 0.7907 - val_loss: 6.8521 - val_categorical_accuracy: 0.1622\n",
      "Epoch 384/2000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.6410 - categorical_accuracy: 0.8023 - val_loss: 6.6535 - val_categorical_accuracy: 0.1622\n",
      "Epoch 385/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.5165 - categorical_accuracy: 0.8256 - val_loss: 8.6975 - val_categorical_accuracy: 0.1081\n",
      "Epoch 386/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.7936 - categorical_accuracy: 0.7791 - val_loss: 7.9893 - val_categorical_accuracy: 0.1081\n",
      "Epoch 387/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.8041 - categorical_accuracy: 0.7209 - val_loss: 7.5172 - val_categorical_accuracy: 0.1622\n",
      "Epoch 388/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4023 - categorical_accuracy: 0.8953 - val_loss: 7.6962 - val_categorical_accuracy: 0.1081\n",
      "Epoch 389/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.4711 - categorical_accuracy: 0.8837 - val_loss: 9.8188 - val_categorical_accuracy: 0.1081\n",
      "Epoch 390/2000\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.9176 - categorical_accuracy: 0.6512 - val_loss: 7.7397 - val_categorical_accuracy: 0.1622\n",
      "Epoch 391/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.4635 - categorical_accuracy: 0.8372 - val_loss: 8.7592 - val_categorical_accuracy: 0.1351\n",
      "Epoch 392/2000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.4144 - categorical_accuracy: 0.8953 - val_loss: 7.0581 - val_categorical_accuracy: 0.1351\n",
      "Epoch 393/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 39ms/step - loss: 0.4991 - categorical_accuracy: 0.8256 - val_loss: 8.5864 - val_categorical_accuracy: 0.1351\n",
      "Epoch 394/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.8960 - categorical_accuracy: 0.7093 - val_loss: 8.3583 - val_categorical_accuracy: 0.1351\n",
      "Epoch 395/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.0932 - categorical_accuracy: 0.6860 - val_loss: 6.9823 - val_categorical_accuracy: 0.1622\n",
      "Epoch 396/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.5822 - categorical_accuracy: 0.8140 - val_loss: 7.1139 - val_categorical_accuracy: 0.1351\n",
      "Epoch 397/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.4558 - categorical_accuracy: 0.8605 - val_loss: 7.5559 - val_categorical_accuracy: 0.1081\n",
      "Epoch 398/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.4607 - categorical_accuracy: 0.8488 - val_loss: 7.6423 - val_categorical_accuracy: 0.1622\n",
      "Epoch 399/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.6094 - categorical_accuracy: 0.8140 - val_loss: 10.0574 - val_categorical_accuracy: 0.1622\n",
      "Epoch 400/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.7893 - categorical_accuracy: 0.7209 - val_loss: 9.0097 - val_categorical_accuracy: 0.1081\n",
      "Epoch 401/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.4602 - categorical_accuracy: 0.8372 - val_loss: 7.6849 - val_categorical_accuracy: 0.1351\n",
      "Epoch 402/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.4551 - categorical_accuracy: 0.8837 - val_loss: 7.1761 - val_categorical_accuracy: 0.1351\n",
      "Epoch 403/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.8185 - categorical_accuracy: 0.7209 - val_loss: 9.1836 - val_categorical_accuracy: 0.1622\n",
      "Epoch 404/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.4932 - categorical_accuracy: 0.8372 - val_loss: 8.0196 - val_categorical_accuracy: 0.1622\n",
      "Epoch 405/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.4073 - categorical_accuracy: 0.8837 - val_loss: 8.6657 - val_categorical_accuracy: 0.1081\n",
      "Epoch 406/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.5666 - categorical_accuracy: 0.8372 - val_loss: 7.9508 - val_categorical_accuracy: 0.1622\n",
      "Epoch 407/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.5366 - categorical_accuracy: 0.8488 - val_loss: 8.0407 - val_categorical_accuracy: 0.1351\n",
      "Epoch 408/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.6525 - categorical_accuracy: 0.7558 - val_loss: 8.5770 - val_categorical_accuracy: 0.1351\n",
      "Epoch 409/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.8230 - categorical_accuracy: 0.7442 - val_loss: 7.5896 - val_categorical_accuracy: 0.1622\n",
      "Epoch 410/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6056 - categorical_accuracy: 0.8023 - val_loss: 7.6451 - val_categorical_accuracy: 0.1622\n",
      "Epoch 411/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3631 - categorical_accuracy: 0.9070 - val_loss: 7.2772 - val_categorical_accuracy: 0.1351\n",
      "Epoch 412/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4106 - categorical_accuracy: 0.8837 - val_loss: 7.8607 - val_categorical_accuracy: 0.1622\n",
      "Epoch 413/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.6056 - categorical_accuracy: 0.7907 - val_loss: 9.9967 - val_categorical_accuracy: 0.0811\n",
      "Epoch 414/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.5557 - categorical_accuracy: 0.7907 - val_loss: 8.8420 - val_categorical_accuracy: 0.1622\n",
      "Epoch 415/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3806 - categorical_accuracy: 0.8605 - val_loss: 8.7901 - val_categorical_accuracy: 0.1351\n",
      "Epoch 416/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.4764 - categorical_accuracy: 0.8140 - val_loss: 8.6960 - val_categorical_accuracy: 0.1081\n",
      "Epoch 417/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.6110 - categorical_accuracy: 0.8256 - val_loss: 8.0504 - val_categorical_accuracy: 0.1081\n",
      "Epoch 418/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.9571 - categorical_accuracy: 0.7558 - val_loss: 9.3960 - val_categorical_accuracy: 0.1351\n",
      "Epoch 419/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4270 - categorical_accuracy: 0.8372 - val_loss: 9.5809 - val_categorical_accuracy: 0.1351\n",
      "Epoch 420/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4249 - categorical_accuracy: 0.8837 - val_loss: 9.7194 - val_categorical_accuracy: 0.1622\n",
      "Epoch 421/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.8902 - categorical_accuracy: 0.7442 - val_loss: 6.6070 - val_categorical_accuracy: 0.1351\n",
      "Epoch 422/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.8123 - categorical_accuracy: 0.7209 - val_loss: 7.7743 - val_categorical_accuracy: 0.1081\n",
      "Epoch 423/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4940 - categorical_accuracy: 0.8605 - val_loss: 8.3448 - val_categorical_accuracy: 0.1622\n",
      "Epoch 424/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3698 - categorical_accuracy: 0.8837 - val_loss: 8.3541 - val_categorical_accuracy: 0.1622\n",
      "Epoch 425/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.8380 - categorical_accuracy: 0.7326 - val_loss: 7.0019 - val_categorical_accuracy: 0.1892\n",
      "Epoch 426/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.3918 - categorical_accuracy: 0.9186 - val_loss: 7.4799 - val_categorical_accuracy: 0.1351\n",
      "Epoch 427/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6507 - categorical_accuracy: 0.7442 - val_loss: 8.1194 - val_categorical_accuracy: 0.1351\n",
      "Epoch 428/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6261 - categorical_accuracy: 0.8256 - val_loss: 9.0000 - val_categorical_accuracy: 0.1892\n",
      "Epoch 429/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3957 - categorical_accuracy: 0.8953 - val_loss: 9.1849 - val_categorical_accuracy: 0.1892\n",
      "Epoch 430/2000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.6553 - categorical_accuracy: 0.8023 - val_loss: 8.5545 - val_categorical_accuracy: 0.1892\n",
      "Epoch 431/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3953 - categorical_accuracy: 0.8837 - val_loss: 9.2898 - val_categorical_accuracy: 0.1081\n",
      "Epoch 432/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6214 - categorical_accuracy: 0.7907 - val_loss: 7.8534 - val_categorical_accuracy: 0.1622\n",
      "Epoch 433/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.3789 - categorical_accuracy: 0.8605 - val_loss: 9.0287 - val_categorical_accuracy: 0.1622\n",
      "Epoch 434/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2930 - categorical_accuracy: 0.9186 - val_loss: 10.3172 - val_categorical_accuracy: 0.0541\n",
      "Epoch 435/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.8600 - categorical_accuracy: 0.6977 - val_loss: 8.3100 - val_categorical_accuracy: 0.1351\n",
      "Epoch 436/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3357 - categorical_accuracy: 0.9070 - val_loss: 8.8944 - val_categorical_accuracy: 0.1892\n",
      "Epoch 437/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3631 - categorical_accuracy: 0.8721 - val_loss: 7.3794 - val_categorical_accuracy: 0.1081\n",
      "Epoch 438/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.2760 - categorical_accuracy: 0.6163 - val_loss: 7.2566 - val_categorical_accuracy: 0.0811\n",
      "Epoch 439/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6297 - categorical_accuracy: 0.7791 - val_loss: 8.2282 - val_categorical_accuracy: 0.1351\n",
      "Epoch 440/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3037 - categorical_accuracy: 0.9302 - val_loss: 8.8141 - val_categorical_accuracy: 0.1622\n",
      "Epoch 441/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2812 - categorical_accuracy: 0.9535 - val_loss: 8.6423 - val_categorical_accuracy: 0.1351\n",
      "Epoch 442/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3000 - categorical_accuracy: 0.9419 - val_loss: 8.8512 - val_categorical_accuracy: 0.1081\n",
      "Epoch 443/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3860 - categorical_accuracy: 0.8605 - val_loss: 8.3153 - val_categorical_accuracy: 0.1892\n",
      "Epoch 444/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2934 - categorical_accuracy: 0.9186 - val_loss: 9.9779 - val_categorical_accuracy: 0.1081\n",
      "Epoch 445/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.5153 - categorical_accuracy: 0.9186 - val_loss: 10.0227 - val_categorical_accuracy: 0.1351\n",
      "Epoch 446/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.5373 - categorical_accuracy: 0.7907 - val_loss: 9.5786 - val_categorical_accuracy: 0.1081\n",
      "Epoch 447/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.1209 - categorical_accuracy: 0.6628 - val_loss: 7.1104 - val_categorical_accuracy: 0.1351\n",
      "Epoch 448/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.4671 - categorical_accuracy: 0.8372 - val_loss: 8.8503 - val_categorical_accuracy: 0.1892\n",
      "Epoch 449/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2654 - categorical_accuracy: 0.9186 - val_loss: 8.4744 - val_categorical_accuracy: 0.1622\n",
      "Epoch 450/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.3026 - categorical_accuracy: 0.9186 - val_loss: 10.0132 - val_categorical_accuracy: 0.0811\n",
      "Epoch 451/2000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.5493 - categorical_accuracy: 0.8488 - val_loss: 8.4603 - val_categorical_accuracy: 0.1892\n",
      "Epoch 452/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2944 - categorical_accuracy: 0.9186 - val_loss: 8.4295 - val_categorical_accuracy: 0.1622\n",
      "Epoch 453/2000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.4596 - categorical_accuracy: 0.8372 - val_loss: 9.9954 - val_categorical_accuracy: 0.1081\n",
      "Epoch 454/2000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.3502 - categorical_accuracy: 0.9186 - val_loss: 10.4067 - val_categorical_accuracy: 0.1081\n",
      "Epoch 455/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.5847 - categorical_accuracy: 0.8140 - val_loss: 8.0732 - val_categorical_accuracy: 0.0811\n",
      "Epoch 456/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.9938 - categorical_accuracy: 0.5698 - val_loss: 8.0944 - val_categorical_accuracy: 0.1351\n",
      "Epoch 457/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6112 - categorical_accuracy: 0.8488 - val_loss: 8.6392 - val_categorical_accuracy: 0.2162\n",
      "Epoch 458/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.3563 - categorical_accuracy: 0.8837 - val_loss: 9.7197 - val_categorical_accuracy: 0.2162\n",
      "Epoch 459/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.2518 - categorical_accuracy: 0.8953 - val_loss: 10.7398 - val_categorical_accuracy: 0.1892\n",
      "Epoch 460/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.2918 - categorical_accuracy: 0.9302 - val_loss: 9.3060 - val_categorical_accuracy: 0.1892\n",
      "Epoch 461/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2749 - categorical_accuracy: 0.9419 - val_loss: 10.6511 - val_categorical_accuracy: 0.2162\n",
      "Epoch 462/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.4266 - categorical_accuracy: 0.8605 - val_loss: 8.4432 - val_categorical_accuracy: 0.0811\n",
      "Epoch 463/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.5147 - categorical_accuracy: 0.8256 - val_loss: 10.2611 - val_categorical_accuracy: 0.1351\n",
      "Epoch 464/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2923 - categorical_accuracy: 0.9535 - val_loss: 10.0958 - val_categorical_accuracy: 0.1351\n",
      "Epoch 465/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3014 - categorical_accuracy: 0.9070 - val_loss: 10.7001 - val_categorical_accuracy: 0.1351\n",
      "Epoch 466/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.0988 - categorical_accuracy: 0.6977 - val_loss: 7.6833 - val_categorical_accuracy: 0.1351\n",
      "Epoch 467/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.7416 - categorical_accuracy: 0.7326 - val_loss: 9.2885 - val_categorical_accuracy: 0.1081\n",
      "Epoch 468/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.5750 - categorical_accuracy: 0.8140 - val_loss: 10.1926 - val_categorical_accuracy: 0.1351\n",
      "Epoch 469/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.3037 - categorical_accuracy: 0.9186 - val_loss: 9.8257 - val_categorical_accuracy: 0.1892\n",
      "Epoch 470/2000\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.3956 - categorical_accuracy: 0.8372 - val_loss: 8.8286 - val_categorical_accuracy: 0.1351\n",
      "Epoch 471/2000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.6590 - categorical_accuracy: 0.8256 - val_loss: 9.2864 - val_categorical_accuracy: 0.1892\n",
      "Epoch 472/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2747 - categorical_accuracy: 0.9070 - val_loss: 9.7482 - val_categorical_accuracy: 0.1081\n",
      "Epoch 473/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2696 - categorical_accuracy: 0.9186 - val_loss: 10.5875 - val_categorical_accuracy: 0.1622\n",
      "Epoch 474/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.2528 - categorical_accuracy: 0.9302 - val_loss: 9.0055 - val_categorical_accuracy: 0.0541\n",
      "Epoch 475/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.9032 - categorical_accuracy: 0.7558 - val_loss: 7.8698 - val_categorical_accuracy: 0.1081\n",
      "Epoch 476/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4601 - categorical_accuracy: 0.8372 - val_loss: 9.3812 - val_categorical_accuracy: 0.1081\n",
      "Epoch 477/2000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.5494 - categorical_accuracy: 0.7209 - val_loss: 8.5942 - val_categorical_accuracy: 0.1351\n",
      "Epoch 478/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.5924 - categorical_accuracy: 0.8023 - val_loss: 9.9279 - val_categorical_accuracy: 0.2162\n",
      "Epoch 479/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3074 - categorical_accuracy: 0.9070 - val_loss: 9.7786 - val_categorical_accuracy: 0.1351\n",
      "Epoch 480/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2130 - categorical_accuracy: 0.9419 - val_loss: 10.5808 - val_categorical_accuracy: 0.1622\n",
      "Epoch 481/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3302 - categorical_accuracy: 0.9186 - val_loss: 10.4798 - val_categorical_accuracy: 0.1622\n",
      "Epoch 482/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6100 - categorical_accuracy: 0.8023 - val_loss: 9.3005 - val_categorical_accuracy: 0.1892\n",
      "Epoch 483/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2872 - categorical_accuracy: 0.9535 - val_loss: 9.9248 - val_categorical_accuracy: 0.1892\n",
      "Epoch 484/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2823 - categorical_accuracy: 0.9419 - val_loss: 8.6763 - val_categorical_accuracy: 0.1081\n",
      "Epoch 485/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3257 - categorical_accuracy: 0.8721 - val_loss: 13.3592 - val_categorical_accuracy: 0.1351\n",
      "Epoch 486/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.9025 - categorical_accuracy: 0.7209 - val_loss: 9.5871 - val_categorical_accuracy: 0.1622\n",
      "Epoch 487/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2959 - categorical_accuracy: 0.9070 - val_loss: 9.3962 - val_categorical_accuracy: 0.1892\n",
      "Epoch 488/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3630 - categorical_accuracy: 0.8837 - val_loss: 8.1610 - val_categorical_accuracy: 0.1081\n",
      "Epoch 489/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.6589 - categorical_accuracy: 0.7791 - val_loss: 9.5042 - val_categorical_accuracy: 0.1622\n",
      "Epoch 490/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2991 - categorical_accuracy: 0.9070 - val_loss: 9.6129 - val_categorical_accuracy: 0.1351\n",
      "Epoch 491/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2917 - categorical_accuracy: 0.8953 - val_loss: 10.1734 - val_categorical_accuracy: 0.1892\n",
      "Epoch 492/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2780 - categorical_accuracy: 0.8837 - val_loss: 9.8821 - val_categorical_accuracy: 0.1892\n",
      "Epoch 493/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3139 - categorical_accuracy: 0.9070 - val_loss: 12.6337 - val_categorical_accuracy: 0.1081\n",
      "Epoch 494/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.8425 - categorical_accuracy: 0.7442 - val_loss: 12.4396 - val_categorical_accuracy: 0.1622\n",
      "Epoch 495/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.9593 - categorical_accuracy: 0.7209 - val_loss: 9.2459 - val_categorical_accuracy: 0.0541\n",
      "Epoch 496/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.3850 - categorical_accuracy: 0.9070 - val_loss: 9.4312 - val_categorical_accuracy: 0.1351\n",
      "Epoch 497/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2013 - categorical_accuracy: 0.9419 - val_loss: 10.1353 - val_categorical_accuracy: 0.1892\n",
      "Epoch 498/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2379 - categorical_accuracy: 0.9419 - val_loss: 10.7305 - val_categorical_accuracy: 0.1622\n",
      "Epoch 499/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1947 - categorical_accuracy: 0.9535 - val_loss: 10.2904 - val_categorical_accuracy: 0.1892\n",
      "Epoch 500/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.8498 - categorical_accuracy: 0.8023 - val_loss: 9.4178 - val_categorical_accuracy: 0.2162\n",
      "Epoch 501/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4031 - categorical_accuracy: 0.8605 - val_loss: 9.2601 - val_categorical_accuracy: 0.1892\n",
      "Epoch 502/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2196 - categorical_accuracy: 0.9302 - val_loss: 10.1977 - val_categorical_accuracy: 0.1892\n",
      "Epoch 503/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2400 - categorical_accuracy: 0.9651 - val_loss: 10.3163 - val_categorical_accuracy: 0.1892\n",
      "Epoch 504/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3443 - categorical_accuracy: 0.8721 - val_loss: 15.2873 - val_categorical_accuracy: 0.1081\n",
      "Epoch 505/2000\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.2591 - categorical_accuracy: 0.7093 - val_loss: 8.8879 - val_categorical_accuracy: 0.1081\n",
      "Epoch 506/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4625 - categorical_accuracy: 0.8605 - val_loss: 11.5602 - val_categorical_accuracy: 0.1622\n",
      "Epoch 507/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.4947 - categorical_accuracy: 0.8953 - val_loss: 11.5800 - val_categorical_accuracy: 0.1351\n",
      "Epoch 508/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3904 - categorical_accuracy: 0.8488 - val_loss: 10.2068 - val_categorical_accuracy: 0.1081\n",
      "Epoch 509/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2478 - categorical_accuracy: 0.9302 - val_loss: 11.7555 - val_categorical_accuracy: 0.1622\n",
      "Epoch 510/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1957 - categorical_accuracy: 0.9419 - val_loss: 13.8986 - val_categorical_accuracy: 0.0811\n",
      "Epoch 511/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.3218 - categorical_accuracy: 0.7093 - val_loss: 9.9648 - val_categorical_accuracy: 0.1351\n",
      "Epoch 512/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3355 - categorical_accuracy: 0.9070 - val_loss: 9.7477 - val_categorical_accuracy: 0.1892\n",
      "Epoch 513/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1713 - categorical_accuracy: 0.9767 - val_loss: 10.4515 - val_categorical_accuracy: 0.1622\n",
      "Epoch 514/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3929 - categorical_accuracy: 0.9070 - val_loss: 10.1069 - val_categorical_accuracy: 0.1351\n",
      "Epoch 515/2000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.3365 - categorical_accuracy: 0.8953 - val_loss: 11.5970 - val_categorical_accuracy: 0.0811\n",
      "Epoch 516/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2289 - categorical_accuracy: 0.9186 - val_loss: 10.7503 - val_categorical_accuracy: 0.1622\n",
      "Epoch 517/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1801 - categorical_accuracy: 0.9302 - val_loss: 10.6174 - val_categorical_accuracy: 0.1081\n",
      "Epoch 518/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.5278 - categorical_accuracy: 0.8605 - val_loss: 10.7510 - val_categorical_accuracy: 0.1892\n",
      "Epoch 519/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.5714 - categorical_accuracy: 0.7907 - val_loss: 10.0064 - val_categorical_accuracy: 0.1081\n",
      "Epoch 520/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.7666 - categorical_accuracy: 0.8023 - val_loss: 8.8607 - val_categorical_accuracy: 0.1351\n",
      "Epoch 521/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3824 - categorical_accuracy: 0.8605 - val_loss: 10.8803 - val_categorical_accuracy: 0.1622\n",
      "Epoch 522/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2429 - categorical_accuracy: 0.9186 - val_loss: 10.3678 - val_categorical_accuracy: 0.1351\n",
      "Epoch 523/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3548 - categorical_accuracy: 0.8605 - val_loss: 10.8500 - val_categorical_accuracy: 0.1622\n",
      "Epoch 524/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2468 - categorical_accuracy: 0.9186 - val_loss: 9.0659 - val_categorical_accuracy: 0.0541\n",
      "Epoch 525/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.8010 - categorical_accuracy: 0.7558 - val_loss: 10.1972 - val_categorical_accuracy: 0.1351\n",
      "Epoch 526/2000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2177 - categorical_accuracy: 0.9535 - val_loss: 10.3735 - val_categorical_accuracy: 0.1081\n",
      "Epoch 527/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2031 - categorical_accuracy: 0.9651 - val_loss: 11.0058 - val_categorical_accuracy: 0.1622\n",
      "Epoch 528/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1786 - categorical_accuracy: 0.9651 - val_loss: 11.0601 - val_categorical_accuracy: 0.1622\n",
      "Epoch 529/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4330 - categorical_accuracy: 0.8488 - val_loss: 9.3009 - val_categorical_accuracy: 0.1351\n",
      "Epoch 530/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.4321 - categorical_accuracy: 0.6744 - val_loss: 10.6600 - val_categorical_accuracy: 0.1622\n",
      "Epoch 531/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2420 - categorical_accuracy: 0.9070 - val_loss: 10.2423 - val_categorical_accuracy: 0.1892\n",
      "Epoch 532/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1589 - categorical_accuracy: 0.9651 - val_loss: 10.8637 - val_categorical_accuracy: 0.1892\n",
      "Epoch 533/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1499 - categorical_accuracy: 0.9767 - val_loss: 10.4755 - val_categorical_accuracy: 0.2162\n",
      "Epoch 534/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2196 - categorical_accuracy: 0.9535 - val_loss: 12.7886 - val_categorical_accuracy: 0.0811\n",
      "Epoch 535/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.3915 - categorical_accuracy: 0.6512 - val_loss: 10.4045 - val_categorical_accuracy: 0.1351\n",
      "Epoch 536/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4353 - categorical_accuracy: 0.8372 - val_loss: 10.6899 - val_categorical_accuracy: 0.1351\n",
      "Epoch 537/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2743 - categorical_accuracy: 0.8953 - val_loss: 10.8155 - val_categorical_accuracy: 0.1622\n",
      "Epoch 538/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1805 - categorical_accuracy: 0.9302 - val_loss: 10.9073 - val_categorical_accuracy: 0.1622\n",
      "Epoch 539/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1880 - categorical_accuracy: 0.9419 - val_loss: 9.5270 - val_categorical_accuracy: 0.1351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.9711 - categorical_accuracy: 0.6860 - val_loss: 10.5976 - val_categorical_accuracy: 0.1892\n",
      "Epoch 541/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3787 - categorical_accuracy: 0.8605 - val_loss: 9.4978 - val_categorical_accuracy: 0.1892\n",
      "Epoch 542/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1819 - categorical_accuracy: 0.9419 - val_loss: 10.2985 - val_categorical_accuracy: 0.1351\n",
      "Epoch 543/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1727 - categorical_accuracy: 0.9419 - val_loss: 11.3012 - val_categorical_accuracy: 0.1622\n",
      "Epoch 544/2000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.2137 - categorical_accuracy: 0.9070 - val_loss: 12.3107 - val_categorical_accuracy: 0.1081\n",
      "Epoch 545/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4298 - categorical_accuracy: 0.8837 - val_loss: 10.7529 - val_categorical_accuracy: 0.1622\n",
      "Epoch 546/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2191 - categorical_accuracy: 0.9186 - val_loss: 9.6683 - val_categorical_accuracy: 0.1081\n",
      "Epoch 547/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1628 - categorical_accuracy: 0.9535 - val_loss: 11.4301 - val_categorical_accuracy: 0.1892\n",
      "Epoch 548/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1893 - categorical_accuracy: 0.9535 - val_loss: 12.6351 - val_categorical_accuracy: 0.1351\n",
      "Epoch 549/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.4392 - categorical_accuracy: 0.6860 - val_loss: 11.5010 - val_categorical_accuracy: 0.1622\n",
      "Epoch 550/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2821 - categorical_accuracy: 0.8605 - val_loss: 10.7974 - val_categorical_accuracy: 0.1622\n",
      "Epoch 551/2000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1473 - categorical_accuracy: 0.9535 - val_loss: 11.2740 - val_categorical_accuracy: 0.1622\n",
      "Epoch 552/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1314 - categorical_accuracy: 0.9535 - val_loss: 11.0588 - val_categorical_accuracy: 0.1892\n",
      "Epoch 553/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.5300 - categorical_accuracy: 0.8488 - val_loss: 9.8348 - val_categorical_accuracy: 0.1351\n",
      "Epoch 554/2000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2293 - categorical_accuracy: 0.9419 - val_loss: 9.9205 - val_categorical_accuracy: 0.1622\n",
      "Epoch 555/2000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1716 - categorical_accuracy: 0.9535 - val_loss: 10.7940 - val_categorical_accuracy: 0.1622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x171b3a610>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(patience=500, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=2000, callbacks=[es], validation_split = 0.3, batch_size = 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80103f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_2 (Masking)          (None, 100, 1662)         0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 32)                162816    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 21)                357       \n",
      "=================================================================\n",
      "Total params: 163,701\n",
      "Trainable params: 163,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3920eb6b",
   "metadata": {},
   "source": [
    "## Make Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6a25e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66395684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'headache'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[30])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1ae0ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 100, 1662)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b5bc43a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pregnant'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[30])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f33a50a",
   "metadata": {},
   "source": [
    "## Save Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2da9bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('action.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c06901d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('action.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d0872e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7cffc83",
   "metadata": {},
   "source": [
    "## Test in Real Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b7695395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8a6f96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "bf7f7525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "infection\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [230]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         sentence \u001b[38;5;241m=\u001b[39m sentence[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m:]\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Viz probabilities\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mprob_viz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(image, (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m40\u001b[39m), (\u001b[38;5;241m245\u001b[39m, \u001b[38;5;241m117\u001b[39m, \u001b[38;5;241m16\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     48\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sentence), (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m30\u001b[39m), \n\u001b[1;32m     49\u001b[0m                cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mLINE_AA)\n",
      "Input \u001b[0;32mIn [213]\u001b[0m, in \u001b[0;36mprob_viz\u001b[0;34m(res, actions, input_frame, colors)\u001b[0m\n\u001b[1;32m      3\u001b[0m output_frame \u001b[38;5;241m=\u001b[39m input_frame\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(res):\n\u001b[0;32m----> 5\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(output_frame, (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m60\u001b[39m\u001b[38;5;241m+\u001b[39mnum\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m40\u001b[39m), (\u001b[38;5;28mint\u001b[39m(prob\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m), \u001b[38;5;241m90\u001b[39m\u001b[38;5;241m+\u001b[39mnum\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m40\u001b[39m), \u001b[43mcolors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(output_frame, actions[num], (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m85\u001b[39m\u001b[38;5;241m+\u001b[39mnum\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m40\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mLINE_AA)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_frame\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.8\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "#         sequence.insert(0,keypoints)\n",
    "#         sequence = sequence[:30]\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            \n",
    "            \n",
    "        #3. Viz logic\n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                if len(sentence) > 0: \n",
    "                    if actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                else:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf7fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "81bba0a3e1aea3246bccf1314a02fd945e9b390bb368e98c40a6cfa7697ea8c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
