{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53569d45",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Packages that need to be imported:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9965be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c9f46",
   "metadata": {},
   "source": [
    "### Read dataframe\n",
    "\n",
    "Read json file with words and the list of videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/dxli94/WLASL/master/start_kit/WLASL_v0.3.json\"\n",
    "df = pd.read_json(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bac149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export a list of words in csv\n",
    "#df[\"gloss\"].to_csv(\"list_words.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34a0dd9",
   "metadata": {},
   "source": [
    "### Filter df only selected words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c543548",
   "metadata": {},
   "source": [
    "Filter the json file with words that will be used to train our model. This file will be used later to download the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_selected_words = [\"headache\", \"cough\", \"sore throat\", \"blood\", \"pregnant\", \"diabetes\", \n",
    "                       \"stomach\",\"pain\", \"allergy\", \"cold\", \"bone\",\"diarrhea\", \"heart\", \"heart attack\", \n",
    "                       \"cochlear implant\", \"vomit\", \"depressed\", \"hurt\", \"infection\", \"tired\", \"thank you\"]\n",
    "\n",
    "df = df[df['gloss'].isin(list_selected_words)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Df shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21de09ed",
   "metadata": {},
   "source": [
    "### Export pandas df to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a0cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_json = df.to_json(\"WLASL_v0.3.json\", orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c911748c",
   "metadata": {},
   "source": [
    "### Explore instances\n",
    "\n",
    "Create a dataframe with video_ids and the corresponding word. Notice that in this step we are using the json file exported in the previous step, which contains information about only 21 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = json.load(open(\"../scripts/WLASL_v0.3.json\"))\n",
    "\n",
    "id_videos = []\n",
    "for entry in content:\n",
    "    word = entry[\"gloss\"]\n",
    "    instances = entry['instances']\n",
    "\n",
    "    for inst in instances:\n",
    "        video_id = inst['video_id']\n",
    "        id_videos.append([word, video_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408351a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_list = pd.DataFrame(id_videos, columns=[\"word\", \"video_id\"])\n",
    "id_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839dd32",
   "metadata": {},
   "source": [
    "Because of problems during download, we were not able to download all video_ids. To count the real number of videos that we have available, we need to check if they are in our folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f096e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_in_folder = []\n",
    "\n",
    "for video_id in id_list.video_id:\n",
    "    if os.path.exists(f'../raw_data/{video_id}.mp4'):\n",
    "        ids_in_folder.append(video_id)\n",
    "\n",
    "print(f\"Number os videos: {len(ids_in_folder)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6361477b",
   "metadata": {},
   "source": [
    "Filter dataframe to only videos available in our folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = id_list[id_list['video_id'].isin(ids_in_folder)]\n",
    "print(f\"Shape new df: {id_list.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29da871",
   "metadata": {},
   "source": [
    "#### Count videos per symptoms\n",
    "Check how many videos we have, by symptom, to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777bc7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_list = id_list.groupby(\"word\").count().reset_index()\n",
    "aux_list.sort_values(\"video_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf61e2",
   "metadata": {},
   "source": [
    "### Setup Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0dc6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('../MP_Data') \n",
    "\n",
    "# Videos are going to be 70 frames in length\n",
    "sequence_length = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b6d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Loop to create folders for each action to be trained\n",
    "# and n_folder depending on the number of videos\n",
    "# ----------------------------------------------------\n",
    "\n",
    "for word in range(19, len(aux_list.word)):   # modificar range depois dos testes (0, len..)\n",
    "    \n",
    "    # Identify how many videos per action\n",
    "    n_folders = aux_list.iloc[word, 1]\n",
    "    \n",
    "    # Create folders\n",
    "    for n in range(n_folders):\n",
    "        try:\n",
    "            folder = os.path.join(DATA_PATH, aux_list.iloc[word, 0], str(n))\n",
    "            os.makedirs(folder)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2f741",
   "metadata": {},
   "source": [
    "### Functions for data detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fa2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediapipe_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9449099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efb9d6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### To check lenght of videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6070511e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to extract video id for selected word - Giovanna \n",
    "def videos_word(word):\n",
    "  \n",
    "    id_list_novo = id_list[id_list['word'] == word]\n",
    "    lista_videos = [video_id for video_id in id_list_novo.video_id]\n",
    "    \n",
    "    return lista_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175eed33",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to return duration and framecount for each video\n",
    "def with_opencv(filename):\n",
    "    import cv2\n",
    "    video = cv2.VideoCapture(filename)\n",
    "\n",
    "    duration = video.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    return duration, frame_count\n",
    "\n",
    "\n",
    "\n",
    "# Get id_videos from function video_words and return lenght\n",
    "n_frames = []\n",
    "\n",
    "for word in aux_list[\"word\"]:\n",
    "    for video_id in videos_word(word):\n",
    "        video = f'../raw_data/{video_id}.mp4'\n",
    "\n",
    "        if os.path.exists(video) == True:\n",
    "            n_frames.append(with_opencv(video)[1])\n",
    "            \n",
    "            \n",
    "# Plot distribution frames \n",
    "plt.title(\"Distribution of Frames\")\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(pd.DataFrame(n_frames), bins=30, color=\"g\", stacked=True);\n",
    "plt.text(80, 15, f'Optimal number \\n of frames=70');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885387f3",
   "metadata": {},
   "source": [
    "### Extract data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Function to extract data points from videos\n",
    "# Action = words\n",
    "# Video_id = name of the video\n",
    "# Sequence = folder in which it will be placed\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def extract_data_points(action, video_id, sequence):\n",
    "    \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "        for frame_num in range(sequence_length):\n",
    "\n",
    "                    # Read feed\n",
    "                    cap = cv2.VideoCapture(f'../raw_data/{video_id}.mp4')\n",
    "                    ret, frame = cap.read()\n",
    "\n",
    "                    # Make detections\n",
    "                    image, results = mediapipe_detection(frame, holistic)\n",
    "                    print(results)\n",
    "\n",
    "                    # Draw landmarks\n",
    "                    draw_styled_landmarks(image, results)\n",
    "\n",
    "                    # Apply wait logic\n",
    "                    if frame_num == 0: \n",
    "                        cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                        cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "                        # Show to screen\n",
    "                        cv2.imshow('OpenCV Feed', image)\n",
    "                        cv2.waitKey(2000)\n",
    "                    else: \n",
    "                        cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                        # Show to screen\n",
    "                        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                    # Export keypoints\n",
    "                    keypoints = extract_keypoints(results)\n",
    "                    npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                    np.save(npy_path, keypoints)\n",
    "\n",
    "                    # Break gracefully\n",
    "                    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Loop to extract data points for each word and video\n",
    "# and save it in the correct folder\n",
    "# ---------------------------------------------------\n",
    "\n",
    "for word in id_list.word.unique():\n",
    "    \n",
    "    if word == \"tired\": #apagar depois dos testes, filtra apenas 1 palavra\n",
    "        \n",
    "        # Filter the dataframe\n",
    "        df_temp = id_list[id_list[\"word\"] == word] \n",
    "\n",
    "        # Get information for each action\n",
    "        for word in range(0, len(df_temp.word)):\n",
    "\n",
    "            action = df_temp.iloc[word, 0]\n",
    "            video_id = df_temp.iloc[word, 1]\n",
    "            sequence = word\n",
    "\n",
    "            # Call the function to extract data points\n",
    "            extract_data_points(action, video_id, sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7e022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d85608e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05be04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b98b8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
